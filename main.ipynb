{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.391723Z",
     "start_time": "2025-07-02T23:01:22.388525Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip3 install scikit-learn==1.6.0 pandas numpy matplotlib seaborn xgboost lime tdqm imblearn shap lime",
   "id": "584ad90aa3b138e3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.451315Z",
     "start_time": "2025-07-02T23:01:22.447085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================\n",
    "# IMPORTAÇÃO DE BIBLIOTECAS\n",
    "# =====================================================================\n",
    "\n",
    "# Manipulação e análise de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Pré-processamento e splitting\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Métricas de avaliação\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, confusion_matrix,\n",
    "    f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc,\n",
    "    precision_recall_curve, average_precision_score, classification_report\n",
    ")\n",
    "\n",
    "# Modelos clássicos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Modelos avançados (boosting)\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Redes neurais (Keras/TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Activation, PReLU, LeakyReLU, Dense, Dropout,\n",
    "    Conv1D, MaxPooling1D, Flatten, BatchNormalization,\n",
    "    LSTM, Bidirectional, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,\n",
    "    TensorBoard, CSVLogger\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Balanceamento de dados\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Interpretabilidade\n",
    "import shap\n",
    "from lime import lime_tabular"
   ],
   "id": "2440bd5a92574909",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.533815Z",
     "start_time": "2025-07-02T23:01:22.505935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================\n",
    "# CONFIGURAÇÕES GERAIS\n",
    "# =====================================================================\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"diabetes_prediction.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduzir verbosidade do TensorFlow\n",
    "\n",
    "# Criar diretório para salvar resultados\n",
    "RESULTS_DIR = \"resultados_diabetes\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/modelos\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/graficos/confusao\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/graficos/roc\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/graficos/importancia\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/graficos/distribuicao\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/graficos/shap\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/graficos/lime\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/logs\", exist_ok=True)\n",
    "os.makedirs(f\"{RESULTS_DIR}/history\", exist_ok=True)"
   ],
   "id": "d72f0d25ad005192",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.586657Z",
     "start_time": "2025-07-02T23:01:22.561268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================\n",
    "# FUNÇÕES DE CARREGAMENTO E PRÉ-PROCESSAMENTO DE DADOS\n",
    "# =====================================================================\n",
    "\n",
    "def carregar_dados(caminho_arquivo, verbose=True):\n",
    "    \"\"\"\n",
    "    Carrega o dataset de predição de diabete e realiza análise exploratória inicial.\n",
    "\n",
    "    Args:\n",
    "        caminho_arquivo (str): Caminho para o arquivo CSV do dataset\n",
    "        verbose (bool): Se True, exibe informações sobre o dataset\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com os dados carregados\n",
    "    \"\"\"\n",
    "    logger.info(f\"Carregando dados de {caminho_arquivo}\")\n",
    "\n",
    "    try:\n",
    "        dataframe = pd.read_csv(caminho_arquivo)\n",
    "        if verbose:\n",
    "            logger.info(f\"Dataset carregado com sucesso. Formato: {dataframe.shape}\")\n",
    "            logger.info(f\"Colunas: {dataframe.columns.tolist()}\")\n",
    "            logger.info(f\"Tipos de dados:\\n{dataframe.dtypes}\")\n",
    "            logger.info(\n",
    "                f\"Distribuição da variável alvo (diabetes):\\n{dataframe['diabetes'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "        return dataframe\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o dataset: {e}\")\n",
    "\n",
    "\n",
    "def analisar_dados(df):\n",
    "    \"\"\"\n",
    "    Realiza análise exploratória detalhada dos dados.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame com os dados\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário com estatísticas e informações da análise\n",
    "    \"\"\"\n",
    "    logger.info(\"Realizando análise exploratória dos dados\")\n",
    "\n",
    "    # Estatísticas básicas\n",
    "    estatisticas = {\n",
    "        'shape': df.shape,\n",
    "        'missing_values': df.isnull().sum().to_dict(),\n",
    "        'dtypes': df.dtypes.to_dict(),\n",
    "        'target_distribution': df['diabetes'].value_counts(normalize=True).to_dict(),\n",
    "        'numeric_stats': df.describe().to_dict(),\n",
    "    }\n",
    "\n",
    "    # Análise de variáveis categóricas\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    estatisticas['categorical_counts'] = {col: df[col].value_counts().to_dict() for col in cat_cols}\n",
    "\n",
    "    # Deteção de outliers (usando IQR)\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    outliers = {}\n",
    "    for col in num_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers[col] = {\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound,\n",
    "            'n_outliers': ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
    "        }\n",
    "    estatisticas['outliers'] = outliers\n",
    "\n",
    "    # Correlações\n",
    "    # Garante que apenas colunas numéricas sejam usadas para correlação\n",
    "    numeric_df = df.select_dtypes(include=np.number)\n",
    "    if 'diabetes' in numeric_df.columns:\n",
    "        estatisticas['correlations'] = numeric_df.corr()['diabetes'].to_dict()\n",
    "    else:\n",
    "        estatisticas['correlations'] = {}\n",
    "        logger.warning(\"Coluna 'diabetes' não encontrada ou não é numérica para cálculo de correlação.\")\n",
    "\n",
    "    # Visualizações\n",
    "    visualizar_analise_exploratoria(df)\n",
    "\n",
    "    return estatisticas\n",
    "\n",
    "\n",
    "def visualizar_analise_exploratoria(dataframe):\n",
    "    \"\"\"\n",
    "    Cria visualizações para análise exploratória dos dados.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame com os dados\n",
    "    \"\"\"\n",
    "    logger.info(\"Gerando visualizações para análise exploratória\")\n",
    "    df = dataframe.select_dtypes(include=np.number)\n",
    "    # Configuração para visualizações\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    sns.set_palette('viridis')\n",
    "\n",
    "    # 1. Distribuição da variável alvo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = sns.countplot(x='diabetes', data=df, palette=['#3498db', '#e74c3c'], hue='diabetes', legend=False)\n",
    "    plt.title('Distribuição da Variável Alvo (Diabetes)', fontsize=15)\n",
    "    plt.xlabel('Diabetes', fontsize=12)\n",
    "    plt.ylabel('Contagem', fontsize=12)\n",
    "\n",
    "    # Adicionar percentagens\n",
    "    total = len(df)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width() / 2., height + 5,\n",
    "                f'{height} ({height / total:.1%})',\n",
    "                ha=\"center\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/distribuicao/distribuicao_target.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Distribuição das variáveis numéricas por status de diabete\n",
    "    num_cols = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        sns.histplot(data=df, x=col, hue='diabetes', kde=True, bins=30,\n",
    "                     palette=['#3498db', '#e74c3c'], alpha=0.6)\n",
    "        plt.title(f'Distribuição de {col} por Status de Diabetes', fontsize=13)\n",
    "        plt.xlabel(col, fontsize=11)\n",
    "        plt.ylabel('Contagem', fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/distribuicao/distribuicao_variaveis_numericas.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Boxplots para variáveis numéricas\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        sns.boxplot(x='diabetes', y=col, data=df, palette=['#3498db', '#e74c3c'], hue='diabetes', legend=False)\n",
    "        plt.title(f'{col} por Status de Diabetes', fontsize=13)\n",
    "        plt.xlabel('Diabetes', fontsize=11)\n",
    "        plt.ylabel(col, fontsize=11)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/boxplots_variaveis_numericas.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 4. Matriz de correlação\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr_matrix = df.corr()\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Matriz de Correlação', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/matriz_correlacao.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 5. Pairplot para variáveis numéricas\n",
    "    sns.pairplot(df[num_cols + ['diabetes']], hue='diabetes',\n",
    "                 palette=['#3498db', '#e74c3c'], diag_kind='kde')\n",
    "    plt.suptitle('Pairplot de Variáveis Numéricas', y=1.02, fontsize=16)\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/pairplot_variaveis_numericas.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 6. Contagem de variáveis categóricas\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    if cat_cols:\n",
    "        plt.figure(figsize=(15, 5 * len(cat_cols)))\n",
    "\n",
    "        for i, col in enumerate(cat_cols):\n",
    "            plt.subplot(len(cat_cols), 1, i + 1)\n",
    "            sns.countplot(x=col, hue='diabetes', data=df, palette=['#3498db', '#e74c3c'], legend=False)\n",
    "            plt.title(f'Distribuição de {col} por Status de Diabetes', fontsize=13)\n",
    "            plt.xlabel(col, fontsize=11)\n",
    "            plt.ylabel('Contagem', fontsize=11)\n",
    "            plt.xticks(rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{RESULTS_DIR}/graficos/distribuicao/distribuicao_variaveis_categoricas.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # 7. Relação entre HbA1c e glicose com diabete\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = sns.scatterplot(data=df, x='HbA1c_level', y='blood_glucose_level',\n",
    "                              hue='diabetes', palette=['#3498db', '#e74c3c'],\n",
    "                              s=80, alpha=0.7)\n",
    "    plt.axvline(x=6.5, color='red', linestyle='--', label='Limiar HbA1c (6.5%)')\n",
    "    plt.axhline(y=126, color='green', linestyle='--', label='Limiar Glicose (126 mg/dL)')\n",
    "\n",
    "    # Adicionar anotações para os quadrantes\n",
    "    plt.text(7.5, 200, 'Alto risco\\n(HbA1c alto, Glicose alta)', fontsize=12, ha='center')\n",
    "    plt.text(5.5, 200, 'Risco moderado\\n(HbA1c normal, Glicose alta)', fontsize=12, ha='center')\n",
    "    plt.text(7.5, 100, 'Risco moderado\\n(HbA1c alto, Glicose normal)', fontsize=12, ha='center')\n",
    "    plt.text(5.5, 100, 'Baixo risco\\n(HbA1c normal, Glicose normal)', fontsize=12, ha='center')\n",
    "\n",
    "    plt.title('Relação entre HbA1c e Glicose no Sangue', fontsize=15)\n",
    "    plt.xlabel('Nível de HbA1c (%)', fontsize=12)\n",
    "    plt.ylabel('Nível de Glicose (mg/dL)', fontsize=12)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/relacao_hba1c_glicose.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def pre_processar_dados(dataframe, metodo_normalizacao='standard',\n",
    "                        metodo_balanceamento='smote',\n",
    "                        tratar_outliers=True,\n",
    "                        metodo_outliers='iqr',\n",
    "                        fator_outliers=1.5,\n",
    "                        percentis_outliers=(5, 95),\n",
    "                        test_size=0.2,\n",
    "                        val_size=0.15,\n",
    "                        random_state=42):\n",
    "    \"\"\"\n",
    "    Realiza o pré-processamento completo dos dados para treinamento do modelo.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame com os dados\n",
    "        metodo_normalizacao (str): Método de normalização ('standard', 'minmax', 'robust')\n",
    "        metodo_balanceamento (str): Método de balanceamento ('smote', 'adasyn', 'borderline', 'tomek', 'none')\n",
    "        tratar_outliers (bool): Se True, trata outliers\n",
    "        metodo_outliers (str): Método para tratar outliers ('iqr', 'zscore', 'percentil', 'isolation_forest', 'winsorization')\n",
    "        fator_outliers (float): Fator multiplicativo para IQR ou threshold para Z-score\n",
    "        percentis_outliers (tuple): Percentis inferior e superior para método percentil\n",
    "        test_size (float): Proporção do conjunto de teste\n",
    "        val_size (float): Proporção do conjunto de validação (em relação ao conjunto não-teste)\n",
    "        random_state (int): Semente aleatória\n",
    "\n",
    "    Returns:\n",
    "        tuple: (x_train, x_val, x_test, y_train, y_val, y_test, preprocessador, feature_names)\n",
    "    \"\"\"\n",
    "    logger.info(\"Iniciando pré-processamento dos dados\")\n",
    "\n",
    "    # Remover valores 'Other' da coluna gender (se existir)\n",
    "    if 'gender' in dataframe.columns and 'Other' in dataframe['gender'].unique():\n",
    "        logger.info(\"Removendo valores 'Other' da coluna gender\")\n",
    "        dataframe = dataframe[dataframe['gender'] != 'Other']\n",
    "\n",
    "    # Separação entre atributos e rótulo\n",
    "    x = dataframe.drop(columns=['diabetes']).copy()\n",
    "    y = dataframe['diabetes'].copy()\n",
    "\n",
    "    # Identificar colunas numéricas e categóricas\n",
    "    colunas_numericas = x.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    colunas_categoricas = x.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    logger.info(f\"Colunas numéricas: {colunas_numericas}\")\n",
    "    logger.info(f\"Colunas categóricas: {colunas_categoricas}\")\n",
    "\n",
    "    # Armazenar nomes das features antes da codificação\n",
    "    feature_names_original = x.columns.tolist()\n",
    "\n",
    "    # Codificar variáveis categóricas\n",
    "    encoder = None\n",
    "    if colunas_categoricas:\n",
    "        logger.info(\"Codificando variáveis categóricas usando One-Hot Encoding\")\n",
    "        encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "        # Aplicar one-hot encoding\n",
    "        categorical_encoded = encoder.fit_transform(x[colunas_categoricas])\n",
    "\n",
    "        # Obter nomes das novas colunas\n",
    "        categorical_feature_names = encoder.get_feature_names_out(colunas_categoricas)\n",
    "\n",
    "        # Criar DataFrame com dados codificados\n",
    "        categorical_df = pd.DataFrame(categorical_encoded,\n",
    "                                    columns=categorical_feature_names,\n",
    "                                    index=x.index)\n",
    "\n",
    "        # Combinar dados numéricos com categóricos codificados\n",
    "        x_processed = pd.concat([x[colunas_numericas], categorical_df], axis=1)\n",
    "\n",
    "        # Atualizar lista de nomes das features\n",
    "        feature_names = colunas_numericas + categorical_feature_names.tolist()\n",
    "\n",
    "        logger.info(f\"Variáveis categóricas codificadas. Novas features: {categorical_feature_names.tolist()}\")\n",
    "    else:\n",
    "        x_processed = x.copy()\n",
    "        feature_names = feature_names_original\n",
    "\n",
    "    # Atualizar lista de colunas numéricas (agora inclui todas as colunas)\n",
    "    colunas_numericas_final = x_processed.columns.tolist()\n",
    "\n",
    "    # Tratamento de outliers\n",
    "    if tratar_outliers:\n",
    "        logger.info(f\"Tratando outliers usando método '{metodo_outliers}'\")\n",
    "        x_processed = tratar_outliers_avancado(\n",
    "            x_processed, colunas_numericas_final,\n",
    "            metodo=metodo_outliers,\n",
    "            fator=fator_outliers,\n",
    "            percentis=percentis_outliers\n",
    "        )\n",
    "\n",
    "    # Normalização\n",
    "    scaler = None\n",
    "    if metodo_normalizacao == 'standard':\n",
    "        logger.info(\"Aplicando normalização padrão (StandardScaler)\")\n",
    "        scaler = StandardScaler()\n",
    "        x_processed[colunas_numericas_final] = scaler.fit_transform(x_processed[colunas_numericas_final])\n",
    "    elif metodo_normalizacao == 'minmax':\n",
    "        logger.info(\"Aplicando normalização Min-Max (MinMaxScaler)\")\n",
    "        scaler = MinMaxScaler()\n",
    "        x_processed[colunas_numericas_final] = scaler.fit_transform(x_processed[colunas_numericas_final])\n",
    "    elif metodo_normalizacao == 'robust':\n",
    "        logger.info(\"Aplicando normalização robusta (RobustScaler)\")\n",
    "        scaler = RobustScaler()\n",
    "        x_processed[colunas_numericas_final] = scaler.fit_transform(x_processed[colunas_numericas_final])\n",
    "    else:\n",
    "        logger.warning(f\"Método de normalização '{metodo_normalizacao}' não reconhecido. Usando dados originais.\")\n",
    "\n",
    "    # Converter para numpy array para algoritmos de balanceamento\n",
    "    x_array = x_processed.values\n",
    "    y_array = y.values\n",
    "\n",
    "    # Balanceamento de classes\n",
    "    if metodo_balanceamento == 'smote':\n",
    "        logger.info(\"Aplicando SMOTE para balanceamento de classes\")\n",
    "        smote = SMOTE(random_state=random_state)\n",
    "        x_array, y_array = smote.fit_resample(x_array, y_array)\n",
    "    elif metodo_balanceamento == 'adasyn':\n",
    "        logger.info(\"Aplicando ADASYN para balanceamento de classes\")\n",
    "        adasyn = ADASYN(random_state=random_state)\n",
    "        x_array, y_array = adasyn.fit_resample(x_array, y_array)\n",
    "    elif metodo_balanceamento == 'borderline':\n",
    "        logger.info(\"Aplicando BorderlineSMOTE para balanceamento de classes\")\n",
    "        borderline = BorderlineSMOTE(random_state=random_state)\n",
    "        x_array, y_array = borderline.fit_resample(x_array, y_array)\n",
    "    elif metodo_balanceamento == 'tomek':\n",
    "        logger.info(\"Aplicando SMOTETomek para balanceamento de classes\")\n",
    "        tomek = SMOTETomek(random_state=random_state)\n",
    "        x_array, y_array = tomek.fit_resample(x_array, y_array)\n",
    "    elif metodo_balanceamento == 'none':\n",
    "        logger.info(\"Nenhum balanceamento aplicado\")\n",
    "    else:\n",
    "        logger.warning(f\"Método de balanceamento '{metodo_balanceamento}' não reconhecido. Usando dados originais.\")\n",
    "\n",
    "    logger.info(f\"Dados após balanceamento: {x_array.shape}, distribuição das classes: {np.bincount(y_array.astype(int))}\")\n",
    "\n",
    "    # Divisão em conjuntos de treino, validação e teste\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "        x_array, y_array, test_size=test_size, random_state=random_state, stratify=y_array\n",
    "    )\n",
    "    x_val, x_test, y_val, y_test = train_test_split(\n",
    "        x_temp, y_temp, test_size=val_size / (test_size), random_state=random_state, stratify=y_temp\n",
    "    )\n",
    "\n",
    "    # Salvar pré-processador\n",
    "    preprocessador = {\n",
    "        'scaler': scaler,\n",
    "        'encoder': encoder,\n",
    "        'feature_selection': None,  # Placeholder para futura seleção de features\n",
    "        'feature_names_original': feature_names_original,\n",
    "        'feature_names_final': feature_names\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Divisão dos dados concluída:\")\n",
    "    logger.info(f\"  Treino: {x_train.shape}\")\n",
    "    logger.info(f\"  Validação: {x_val.shape}\")\n",
    "    logger.info(f\"  Teste: {x_test.shape}\")\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test, preprocessador, feature_names\n",
    "\n",
    "\n",
    "def tratar_outliers_avancado(df, colunas_numericas, metodo='iqr', fator=1.5, percentis=(5, 95)):\n",
    "    \"\"\"\n",
    "    Trata outliers de forma mais eficiente usando diferentes métodos.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame com os dados\n",
    "        colunas_numericas (list): Lista de colunas numéricas\n",
    "        metodo (str): Método para tratar outliers ('iqr', 'zscore', 'percentil', 'isolation_forest')\n",
    "        fator (float): Fator multiplicativo para IQR ou threshold para Z-score\n",
    "        percentis (tuple): Percentis inferior e superior para método percentil\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com outliers tratados\n",
    "    \"\"\"\n",
    "    df_tratado = df.copy()\n",
    "\n",
    "    if metodo == 'iqr':\n",
    "        logger.info(f\"Tratando outliers usando IQR com fator {fator}\")\n",
    "        # Calcular todos os quantis de uma vez (operação vetorizada)\n",
    "        q1 = df_tratado[colunas_numericas].quantile(0.25)\n",
    "        q3 = df_tratado[colunas_numericas].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bounds = q1 - fator * iqr\n",
    "        upper_bounds = q3 + fator * iqr\n",
    "\n",
    "        # Aplicar capping vetorizado\n",
    "        df_tratado[colunas_numericas] = df_tratado[colunas_numericas].clip(\n",
    "            lower=lower_bounds, upper=upper_bounds, axis=1\n",
    "        )\n",
    "\n",
    "    elif metodo == 'zscore':\n",
    "        logger.info(f\"Tratando outliers usando Z-score com threshold {fator}\")\n",
    "        from scipy import stats\n",
    "\n",
    "        # Calcular Z-scores para todas as colunas\n",
    "        z_scores = np.abs(stats.zscore(df_tratado[colunas_numericas]))\n",
    "\n",
    "        # Criar máscara para outliers\n",
    "        outlier_mask = (z_scores > fator).any(axis=1)\n",
    "        logger.info(f\"Identificados {outlier_mask.sum()} outliers com Z-score > {fator}\")\n",
    "\n",
    "        # Substituir outliers pela mediana da coluna\n",
    "        for col in colunas_numericas:\n",
    "            col_z_scores = np.abs(stats.zscore(df_tratado[col]))\n",
    "            outliers = col_z_scores > fator\n",
    "            mediana = df_tratado[col].median()\n",
    "            df_tratado.loc[outliers, col] = mediana\n",
    "\n",
    "    elif metodo == 'percentil':\n",
    "        logger.info(f\"Tratando outliers usando percentis {percentis}\")\n",
    "        # Calcular percentis para todas as colunas\n",
    "        lower_bounds = df_tratado[colunas_numericas].quantile(percentis[0]/100)\n",
    "        upper_bounds = df_tratado[colunas_numericas].quantile(percentis[1]/100)\n",
    "\n",
    "        # Aplicar capping vetorizado\n",
    "        df_tratado[colunas_numericas] = df_tratado[colunas_numericas].clip(\n",
    "            lower=lower_bounds, upper=upper_bounds, axis=1\n",
    "        )\n",
    "\n",
    "    elif metodo == 'isolation_forest':\n",
    "        logger.info(\"Tratando outliers usando Isolation Forest\")\n",
    "        from sklearn.ensemble import IsolationForest\n",
    "\n",
    "        # Treinar Isolation Forest\n",
    "        iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "        outlier_pred = iso_forest.fit_predict(df_tratado[colunas_numericas])\n",
    "\n",
    "        # Identificar outliers (-1 indica outlier)\n",
    "        outliers = outlier_pred == -1\n",
    "        logger.info(f\"Identificados {outliers.sum()} outliers com Isolation Forest\")\n",
    "\n",
    "        # Substituir outliers pela mediana\n",
    "        for col in colunas_numericas:\n",
    "            mediana = df_tratado[col].median()\n",
    "            df_tratado.loc[outliers, col] = mediana\n",
    "\n",
    "    elif metodo == 'winsorization':\n",
    "        logger.info(f\"Tratando outliers usando Winsorização com percentis {percentis}\")\n",
    "        from scipy.stats.mstats import winsorize\n",
    "\n",
    "        # Aplicar winsorização para cada coluna\n",
    "        for col in colunas_numericas:\n",
    "            df_tratado[col] = winsorize(\n",
    "                df_tratado[col],\n",
    "                limits=((100-percentis[1])/100, (100-percentis[0])/100)\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Método '{metodo}' não reconhecido. Use 'iqr', 'zscore', 'percentil', 'isolation_forest' ou 'winsorization'\")\n",
    "\n",
    "    # Calcular estatísticas de outliers removidos\n",
    "    outliers_removidos = {}\n",
    "    for col in colunas_numericas:\n",
    "        valores_originais = df[col]\n",
    "        valores_tratados = df_tratado[col]\n",
    "        modificados = (valores_originais != valores_tratados).sum()\n",
    "        outliers_removidos[col] = {\n",
    "            'modificados': modificados,\n",
    "            'percentual': (modificados / len(df)) * 100\n",
    "        }\n",
    "\n",
    "    logger.info(\"Resumo do tratamento de outliers:\")\n",
    "    for col, stats in outliers_removidos.items():\n",
    "        logger.info(f\"{col}: {stats['modificados']} valores modificados ({stats['percentual']:.2f}%)\")\n",
    "\n",
    "    return df_tratado"
   ],
   "id": "169a4c5e7493d5c5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.625438Z",
     "start_time": "2025-07-02T23:01:22.611573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================\n",
    "# FUNÇÕES PARA CRIAÇÃO DE MODELOS\n",
    "# =====================================================================\n",
    "\n",
    "def criar_modelo_mlp(input_shape,\n",
    "                     camadas=[128, 64, 32],\n",
    "                     activations=['relu', 'relu', 'relu'],\n",
    "                     dropout_rates=[0.3, 0.3, 0.3],\n",
    "                     regularization=0.001,\n",
    "                     learning_rate=0.005,\n",
    "                     batch_norm=True):\n",
    "    \"\"\"\n",
    "    Cria um modelo MLP (Perceptron Multicamadas) para classificação binária.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Forma dos dados de entradas\n",
    "        camadas (list): Lista com o número de neurônios em cada camada oculta\n",
    "        activations (list): Lista com as funções de ativação para cada camada\n",
    "        dropout_rates (list): Lista com as taxas de dropout para cada camada\n",
    "        regularization (float): Coeficiente de regularização L2\n",
    "        learning_rate (float): Taxa de aprendizado\n",
    "        batch_norm (bool): Se True, adiciona camadas de Batch Normalization\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Modelo MLP compilado\n",
    "    \"\"\"\n",
    "    logger.info(f\"Criando modelo MLP com {len(camadas)} camadas ocultas\")\n",
    "    logger.info(f\"Arquitetura: {camadas}\")\n",
    "    logger.info(f\"Ativações: {activations}\")\n",
    "    logger.info(f\"Dropout rates: {dropout_rates}\")\n",
    "\n",
    "    # Verificar se os parâmetros têm o mesmo comprimento\n",
    "    assert len(camadas) == len(activations) == len(dropout_rates), \\\n",
    "        \"camadas, ativacoes e dropout_rates devem ter o mesmo comprimento\"\n",
    "\n",
    "    # Criar modelo\n",
    "    model = Sequential()\n",
    "\n",
    "    # Camada de entrada\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # Camadas ocultas\n",
    "    for i, (units, activation, dropout_rate) in enumerate(zip(camadas, activations, dropout_rates)):\n",
    "        # Adicionar camada densa com regularização L2\n",
    "        model.add(Dense(\n",
    "            units=units,\n",
    "            kernel_regularizer=l2(regularization),\n",
    "            name=f'dense_{i + 1}'\n",
    "        ))\n",
    "\n",
    "        # Adicionar batch normalization antes da ativação\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization(name=f'batch_norm_{i + 1}'))\n",
    "\n",
    "        # Adicionar função de ativação\n",
    "        if activation == 'leaky_relu':\n",
    "            model.add(LeakyReLU(alpha=0.1, name=f'leaky_relu_{i + 1}'))\n",
    "        elif activation == 'prelu':\n",
    "            model.add(PReLU(name=f'prelu_{i + 1}'))\n",
    "        else:\n",
    "            model.add(Activation(activation, name=f'activation_{i + 1}'))\n",
    "\n",
    "        # Adicionar dropout para regularização\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate, name=f'dropout_{i + 1}'))\n",
    "\n",
    "    # Camada de saída\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "    # Compilar modelo\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'recall'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Resumo do modelo\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def criar_modelo_cnn(input_shape,\n",
    "                     filtros=[64, 32, 16],\n",
    "                     kernel_sizes=[3, 3, 3],\n",
    "                     ativacoes=['relu', 'relu', 'relu'],\n",
    "                     dropout_rates=[0.3, 0.3, 0.3],\n",
    "                     pool_sizes=[2, 2, 2],\n",
    "                     regularizacao=0.001,\n",
    "                     learning_rate=0.001,\n",
    "                     batch_norm=True):\n",
    "    \"\"\"\n",
    "    Cria um modelo CNN 1D para classificação binária de dados tabulares.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Forma dos dados de entrada (deve ser 3D para CNN)\n",
    "        filtros (list): Lista com o número de filtros em cada camada convolucional\n",
    "        kernel_sizes (list): Lista com os tamanhos do kernel para cada camada\n",
    "        ativacoes (list): Lista com as funções de ativação para cada camada\n",
    "        dropout_rates (list): Lista com as taxas de dropout para cada camada\n",
    "        pool_sizes (list): Lista com os tamanhos de pooling para cada camada\n",
    "        regularizacao (float): Coeficiente de regularização L2\n",
    "        learning_rate (float): Taxa de aprendizado\n",
    "        batch_norm (bool): Se True, adiciona camadas de Batch Normalization\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Modelo CNN compilado\n",
    "    \"\"\"\n",
    "    logger.info(f\"Criando modelo CNN com {len(filtros)} camadas convolucionais\")\n",
    "    logger.info(f\"Filtros: {filtros}\")\n",
    "    logger.info(f\"Kernel sizes: {kernel_sizes}\")\n",
    "    logger.info(f\"Ativações: {ativacoes}\")\n",
    "\n",
    "    # Verificar se os parâmetros têm o mesmo comprimento\n",
    "    assert len(filtros) == len(kernel_sizes) == len(ativacoes) == len(dropout_rates) == len(pool_sizes), \\\n",
    "        \"filtros, kernel_sizes, ativacoes, dropout_rates e pool_sizes devem ter o mesmo comprimento\"\n",
    "\n",
    "    # Verificar se a forma de entrada é 3D\n",
    "    if len(input_shape) != 2:\n",
    "        logger.warning(f\"Input shape {input_shape} não é 3D. Adicionando dimensão extra.\")\n",
    "        input_shape = (*input_shape, 1)\n",
    "\n",
    "    # Criar modelo\n",
    "    model = Sequential()\n",
    "\n",
    "    # Camada de entrada\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # Camadas convolucionais\n",
    "    for i, (filters, kernel_size, activation, dropout_rate, pool_size) in enumerate(\n",
    "            zip(filtros, kernel_sizes, ativacoes, dropout_rates, pool_sizes)):\n",
    "\n",
    "        # Adicionar camada convolucional com regularização L2\n",
    "        model.add(Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same',\n",
    "            kernel_regularizer=l2(regularizacao),\n",
    "            name=f'conv_{i + 1}'\n",
    "        ))\n",
    "\n",
    "        # Adicionar batch normalization antes da ativação\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization(name=f'batch_norm_{i + 1}'))\n",
    "\n",
    "        # Adicionar função de ativação\n",
    "        if activation == 'leaky_relu':\n",
    "            model.add(LeakyReLU(alpha=0.1, name=f'leaky_relu_{i + 1}'))\n",
    "        elif activation == 'prelu':\n",
    "            model.add(PReLU(name=f'prelu_{i + 1}'))\n",
    "        else:\n",
    "            model.add(Activation(activation, name=f'activation_{i + 1}'))\n",
    "\n",
    "        # Adicionar max pooling\n",
    "        model.add(MaxPooling1D(pool_size=pool_size, padding='same', name=f'pool_{i + 1}'))\n",
    "\n",
    "        # Adicionar dropout para regularização\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate, name=f'dropout_{i + 1}'))\n",
    "\n",
    "    # Flatten para conectar às camadas densas\n",
    "    model.add(Flatten(name='flatten'))\n",
    "\n",
    "    # Camada densa intermediária\n",
    "    model.add(Dense(32, kernel_regularizer=l2(regularizacao), name='dense_1'))\n",
    "    if batch_norm:\n",
    "        model.add(BatchNormalization(name='batch_norm_dense'))\n",
    "    model.add(Activation('relu', name='activation_dense'))\n",
    "    model.add(Dropout(0.3, name='dropout_dense'))\n",
    "\n",
    "    # Camada de saída\n",
    "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "    # Compilar modelo\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'recall'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Resumo do modelo\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def criar_modelo_hibrido(input_shape,\n",
    "                         filtros_cnn=[64, 32],\n",
    "                         kernel_sizes=[3, 3],\n",
    "                         unidades_lstm=32,\n",
    "                         unidades_densas=[64, 32],\n",
    "                         ativacoes=['relu', 'relu'],\n",
    "                         dropout_rates=[0.3, 0.3],\n",
    "                         regularizacao=0.001,\n",
    "                         learning_rate=0.001,\n",
    "                         batch_norm=True):\n",
    "    \"\"\"\n",
    "    Cria um modelo híbrido CNN-LSTM para classificação binária de dados tabulares.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Forma dos dados de entrada (deve ser 3D)\n",
    "        filtros_cnn (list): Lista com o número de filtros em cada camada convolucional\n",
    "        kernel_sizes (list): Lista com os tamanhos do kernel para cada camada\n",
    "        unidades_lstm (int): Número de unidades na camada LSTM\n",
    "        unidades_densas (list): Lista com o número de neurônios em cada camada densa\n",
    "        ativacoes (list): Lista com as funções de ativação para cada camada densa\n",
    "        dropout_rates (list): Lista com as taxas de dropout para cada camada densa\n",
    "        regularizacao (float): Coeficiente de regularização L2\n",
    "        learning_rate (float): Taxa de aprendizado\n",
    "        batch_norm (bool): Se True, adiciona camadas de Batch Normalization\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Modelo híbrido CNN-LSTM compilado\n",
    "    \"\"\"\n",
    "    logger.info(\"Criando modelo híbrido CNN-LSTM\")\n",
    "    logger.info(f\"Filtros CNN: {filtros_cnn}\")\n",
    "    logger.info(f\"Unidades LSTM: {unidades_lstm}\")\n",
    "    logger.info(f\"Unidades densas: {unidades_densas}\")\n",
    "\n",
    "    # Verificar se a forma de entrada é 3D\n",
    "    if len(input_shape) != 2:\n",
    "        logger.warning(f\"Input shape {input_shape} não é 3D. Adicionando dimensão extra.\")\n",
    "        input_shape = (*input_shape, 1)\n",
    "\n",
    "    # Verificar se os parâmetros têm o mesmo comprimento\n",
    "    assert len(filtros_cnn) == len(kernel_sizes), \\\n",
    "        \"filtros_cnn e kernel_sizes devem ter o mesmo comprimento\"\n",
    "    assert len(unidades_densas) == len(ativacoes) == len(dropout_rates), \\\n",
    "        \"unidades_densas, ativacoes e dropout_rates devem ter o mesmo comprimento\"\n",
    "\n",
    "    # Criar modelo usando a API funcional\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Camadas convolucionais\n",
    "    x = inputs\n",
    "    for i, (filters, kernel_size) in enumerate(zip(filtros_cnn, kernel_sizes)):\n",
    "        x = Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding='same',\n",
    "            kernel_regularizer=l2(regularizacao),\n",
    "            name=f'conv_{i + 1}'\n",
    "        )(x)\n",
    "\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization(name=f'batch_norm_conv_{i + 1}')(x)\n",
    "\n",
    "        x = Activation('relu', name=f'activation_conv_{i + 1}')(x)\n",
    "        x = MaxPooling1D(pool_size=2, padding='same', name=f'pool_{i + 1}')(x)\n",
    "\n",
    "    # Camada LSTM bidirecional\n",
    "    x = Bidirectional(LSTM(unidades_lstm, return_sequences=True, name='lstm_1'))(x)\n",
    "    x = Dropout(0.3, name='dropout_lstm')(x)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = GlobalAveragePooling1D(name='global_avg_pool')(x)\n",
    "\n",
    "    # Camadas densas\n",
    "    for i, (units, activation, dropout_rate) in enumerate(zip(unidades_densas, ativacoes, dropout_rates)):\n",
    "        x = Dense(units, kernel_regularizer=l2(regularizacao), name=f'dense_{i + 1}')(x)\n",
    "\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization(name=f'batch_norm_dense_{i + 1}')(x)\n",
    "\n",
    "        if activation == 'leaky_relu':\n",
    "            x = LeakyReLU(alpha=0.1, name=f'leaky_relu_{i + 1}')(x)\n",
    "        elif activation == 'prelu':\n",
    "            x = PReLU(name=f'prelu_{i + 1}')(x)\n",
    "        else:\n",
    "            x = Activation(activation, name=f'activation_dense_{i + 1}')(x)\n",
    "\n",
    "        if dropout_rate > 0:\n",
    "            x = Dropout(dropout_rate, name=f'dropout_dense_{i + 1}')(x)\n",
    "\n",
    "    # Camada de saída\n",
    "    outputs = Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    # Criar e compilar modelo\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'recall'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Resumo do modelo\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def criar_callbacks(nome_modelo, paciencia=10, min_delta=0.001, fator_reducao=0.5, min_lr=1e-6):\n",
    "    \"\"\"\n",
    "    Cria callbacks para treinamento do modelo.\n",
    "\n",
    "    Args:\n",
    "        nome_modelo (str): Nome do modelo para salvar\n",
    "        paciencia (int): Número de épocas para esperar antes de parar o treinamento\n",
    "        min_delta (float): Mínima mudança para considerar como melhoria\n",
    "        fator_reducao (float): Fator para reduzir a taxa de aprendizado\n",
    "        min_lr (float): Taxa de aprendizado mínima\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de callbacks\n",
    "    \"\"\"\n",
    "    # Criar diretório para ‘logs’ do TensorBoard\n",
    "    log_dir = f\"{RESULTS_DIR}/logs/{nome_modelo}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        # Early stopping para evitar overfitting\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=paciencia,\n",
    "            min_delta=min_delta,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        # Model checkpoint para salvar o melhor modelo\n",
    "        ModelCheckpoint(\n",
    "            filepath=f\"{RESULTS_DIR}/modelos/{nome_modelo}_best.h5\",\n",
    "            monitor='val_auc',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        # Reduce learning rate quando o treinamento estagnar\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=fator_reducao,\n",
    "            patience=paciencia // 2,\n",
    "            min_lr=min_lr,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        # TensorBoard para visualização do treino\n",
    "        TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            update_freq='epoch'\n",
    "        ),\n",
    "\n",
    "        # CSV Logger para salvar histórico de treino\n",
    "        CSVLogger(\n",
    "            filename=f\"{RESULTS_DIR}/history/{nome_modelo}_history.csv\",\n",
    "            separator=',',\n",
    "            append=False\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return callbacks"
   ],
   "id": "d4f2ceb2634d7b79",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.673962Z",
     "start_time": "2025-07-02T23:01:22.662514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================\n",
    "# FUNÇÕES PARA COMPARAÇÃO DE MODELOS\n",
    "# =====================================================================\n",
    "\n",
    "def treinar_modelos_classicos(x_train, y_train, x_test, y_test, feature_names):\n",
    "    \"\"\"\n",
    "    Treina e avalia modelos clássicos de machine learning.\n",
    "\n",
    "    Args:\n",
    "        x_train (np.ndarray): Dados de treinamento\n",
    "        y_train (np.ndarray): Rótulos de treinamento\n",
    "        x_test (np.ndarray): Dados de teste\n",
    "        y_test (np.ndarray): Rótulos de teste\n",
    "        feature_names (list): Nomes das features\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com resultados dos modelos\n",
    "    \"\"\"\n",
    "    logger.info(\"Treinando modelos clássicos de machine learning\")\n",
    "\n",
    "    # Garantir que x_train e x_test sejam DataFrames com nomes de features\n",
    "    if not isinstance(x_train, pd.DataFrame):\n",
    "        x_train = pd.DataFrame(x_train, columns=feature_names)\n",
    "    if not isinstance(x_test, pd.DataFrame):\n",
    "        x_test = pd.DataFrame(x_test, columns=feature_names)\n",
    "\n",
    "    # Definir modelos\n",
    "    modelos = {\n",
    "        'Regressão Logística': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced', verbose=1),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', verbose=1),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42, verbose=1),\n",
    "        'XGBoost': XGBClassifier(eval_metric='logloss', use_label_encoder=False, random_state=42, verbose=1, n_jobs=-1),\n",
    "        'LightGBM': LGBMClassifier(random_state=42, verbose=1, n_jobs=-1),\n",
    "        'SVM': SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced', verbose=1),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "    }\n",
    "\n",
    "    # Resultados\n",
    "    resultados = []\n",
    "\n",
    "    # Treinar e avaliar cada modelo\n",
    "    for nome, modelo in modelos.items():\n",
    "        logger.info(f\"Treinando modelo: {nome}\")\n",
    "\n",
    "        # Treinar modelo\n",
    "        modelo.fit(x_train, y_train)\n",
    "\n",
    "        # Fazer predições\n",
    "        y_pred = modelo.predict(x_test)\n",
    "\n",
    "        # Obter probabilidades\n",
    "        if hasattr(modelo, \"predict_proba\"):\n",
    "            y_prob = modelo.predict_proba(x_test)[:, 1]\n",
    "        else:\n",
    "            # Para SVM sem probabilidades\n",
    "            y_prob = modelo.decision_function(x_test)\n",
    "            # Normalizar para [0, 1]\n",
    "            y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())\n",
    "\n",
    "        # Calcular métricas\n",
    "        metrics = {\n",
    "            'modelo': nome,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_prob),\n",
    "            'average_precision': average_precision_score(y_test, y_prob)\n",
    "        }\n",
    "\n",
    "        resultados.append(metrics)\n",
    "\n",
    "        # Salvar modelo\n",
    "        with open(f\"{RESULTS_DIR}/modelos/modelo_{nome.replace(' ', '_').lower()}.pkl\", 'wb') as f:\n",
    "            pickle.dump(modelo, f)\n",
    "\n",
    "        # Visualizar matriz de confusão\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Matriz de Confusão - {nome}', fontsize=15)\n",
    "        plt.ylabel('Valor Real', fontsize=12)\n",
    "        plt.xlabel('Valor Predito', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{RESULTS_DIR}/graficos/confusao/matriz_confusao_{nome.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Visualizar curva ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "        plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "        plt.title(f'Curva ROC - {nome}', fontsize=15)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{RESULTS_DIR}/graficos/roc/curva_roc_{nome.replace(' ', '_').lower()}.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Para Random Forest, visualizar importância das features\n",
    "        if nome == 'Random Forest':\n",
    "            importances = modelo.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.bar(range(len(indices[:15])), importances[indices[:15]], align='center')\n",
    "            plt.xticks(range(len(indices[:15])), [feature_names[i] for i in indices[:15]], rotation=90)\n",
    "            plt.title('Importância das Features - Random Forest', fontsize=15)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{RESULTS_DIR}/graficos/importancia/importancia_features_random_forest.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    # Criar DataFrame com resultados\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "\n",
    "    # Salvar resultados\n",
    "    resultados_df.to_csv(f\"{RESULTS_DIR}/resultados_modelos_classicos.csv\", index=False)\n",
    "\n",
    "    return resultados_df\n",
    "\n",
    "\n",
    "def comparar_todos_modelos(resultados_classicos, resultados_redes):\n",
    "    \"\"\"\n",
    "    Compara todos os modelos treinados.\n",
    "\n",
    "    Args:\n",
    "        resultados_classicos (pd.DataFrame): Resultados dos modelos clássicos\n",
    "        resultados_redes (pd.DataFrame): Resultados das redes neurais\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com resultados de todos os modelos\n",
    "    \"\"\"\n",
    "    logger.info(\"Comparando todos os modelos\")\n",
    "\n",
    "    # Combinar resultados\n",
    "    todos_resultados = pd.concat([resultados_classicos, resultados_redes], ignore_index=True)\n",
    "\n",
    "    # Ordenar por F1-score\n",
    "    todos_resultados_sorted = todos_resultados.sort_values('f1', ascending=False)\n",
    "\n",
    "    # Salvar resultados\n",
    "    todos_resultados_sorted.to_csv(f\"{RESULTS_DIR}/resultados_todos_modelos.csv\", index=False)\n",
    "\n",
    "    # Métricas para visualização\n",
    "    metricas = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "    # Visualizar comparação de métricas\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    for i, metrica in enumerate(metricas, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.barplot(x='modelo', y=metrica, data=todos_resultados_sorted, palette='viridis', hue='modelo', legend=False)\n",
    "        plt.title(f'{metrica.upper()}', fontsize=15)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle('Comparação de Métricas entre Modelos', fontsize=20, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/comparacao_metricas_todos_modelos.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Gráfico de radar\n",
    "    # Selecionar top 5 modelos\n",
    "    top_modelos = todos_resultados_sorted.head(5)\n",
    "\n",
    "    # Preparar dados para gráfico de radar\n",
    "    categories = metricas\n",
    "    N = len(categories)\n",
    "\n",
    "    # Criar ângulos para o gráfico de radar\n",
    "    angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "    angles += angles[:1]  # Fechar o círculo\n",
    "\n",
    "    # Criar figura\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    # Adicionar linhas de grade\n",
    "    plt.xticks(angles[:-1], categories, size=12)\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.2, 0.4, 0.6, 0.8, 1.0], [\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], size=10)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    # Plotar cada modelo\n",
    "    for i, row in top_modelos.iterrows():\n",
    "        values = row[metricas].values.tolist()\n",
    "        values += values[:1]  # Fechar o círculo\n",
    "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=row['modelo'])\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "    # Adicionar legenda\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "\n",
    "    plt.title('Comparação dos Top 5 Modelos', size=20, y=1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/radar_top_modelos.png\", dpi=300)\n",
    "    plt.close()"
   ],
   "id": "a32b20b45289c00b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.730691Z",
     "start_time": "2025-07-02T23:01:22.712344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================\n",
    "# FUNÇÕES PARA TREINAMENTO E AVALIAÇÃO DE MODELOS\n",
    "# =====================================================================\n",
    "\n",
    "def treinar_modelo(modelo, x_train, y_train, x_val, y_val,\n",
    "                   nome_modelo, batch_size=32, epochs=100,\n",
    "                   class_weight=None, verbose=1):\n",
    "    \"\"\"\n",
    "    Treina o modelo de rede neural.\n",
    "\n",
    "    Args:\n",
    "        modelo (tf.keras.Model): Modelo a ser treinado\n",
    "        x_train (np.ndarray): Dados de treinos\n",
    "        y_train (np.ndarray): Rótulos de treinos\n",
    "        x_val (np.ndarray): Dados de validação\n",
    "        y_val (np.ndarray): Rótulos de validação\n",
    "        nome_modelo (str): Nome do modelo para salvar\n",
    "        batch_size (int): Tamanho do batch\n",
    "        epochs (int): Número máximo de épocas\n",
    "        class_weight (dict): Pesos para as classes\n",
    "        verbose (int): Nível de verbosidade\n",
    "\n",
    "    Returns:\n",
    "        tuple: (modelo treinado, histórico de treinos)\n",
    "    \"\"\"\n",
    "    logger.info(f\"Iniciando treinamento do modelo {nome_modelo}\")\n",
    "    logger.info(f\"Batch size: {batch_size}, Épocas: {epochs}\")\n",
    "\n",
    "    # Verificar se é necessário reshape para CNN ou modelos híbridos\n",
    "    if 'cnn' in nome_modelo.lower() or 'hibrido' in nome_modelo.lower():\n",
    "        if len(x_train.shape) == 2:\n",
    "            logger.info(\"Adicionando dimensão extra para dados CNN/híbridos\")\n",
    "            x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "            x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
    "\n",
    "    # Calcular class weights se não fornecidos\n",
    "    if class_weight is None and len(np.unique(y_train)) == 2:\n",
    "        logger.info(\"Calculando pesos de classe para balanceamento\")\n",
    "        n_samples = len(y_train)\n",
    "        n_positives = np.sum(y_train)\n",
    "        n_negatives = n_samples - n_positives\n",
    "\n",
    "        weight_for_0 = (1 / n_negatives) * (n_samples / 2.0)\n",
    "        weight_for_1 = (1 / n_positives) * (n_samples / 2.0)\n",
    "\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "        logger.info(f\"Class weights: {class_weight}\")\n",
    "\n",
    "    # Criar callbacks\n",
    "    callbacks = criar_callbacks(nome_modelo)\n",
    "\n",
    "    # Registrar tempo de início\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = modelo.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        class_weight=class_weight,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # Calcular tempo de treinamento\n",
    "    training_time = time.time() - start_time\n",
    "    logger.info(f\"Treinamento concluído em {training_time:.2f} segundos\")\n",
    "\n",
    "    # Carregar o melhor modelo\n",
    "    try:\n",
    "        logger.info(f\"Carregando o melhor modelo de {RESULTS_DIR}/modelos/{nome_modelo}_best.h5\")\n",
    "        modelo = load_model(f\"{RESULTS_DIR}/modelos/{nome_modelo}_best.h5\")\n",
    "    except:\n",
    "        logger.warning(\"Não foi possível carregar o melhor modelo. Usando o modelo atual.\")\n",
    "\n",
    "    # Salvar o modelo final\n",
    "    modelo.save(f\"{RESULTS_DIR}/modelos/{nome_modelo}_final.h5\")\n",
    "    logger.info(f\"Modelo final salvo em {RESULTS_DIR}/modelos/{nome_modelo}_final.h5\")\n",
    "\n",
    "    # Salvar histórico de treino\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.to_csv(f\"{RESULTS_DIR}/history/{nome_modelo}_history_full.csv\", index=False)\n",
    "\n",
    "\n",
    "def avaliar_modelo(modelo, x_test, y_test, nome_modelo, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Avalia o desempenho do modelo nos dados de teste.\n",
    "\n",
    "    Args:\n",
    "        modelo (tf.keras.Model): Modelo treinado\n",
    "        x_test (np.ndarray): Dados de teste\n",
    "        y_test (np.ndarray): Rótulos de teste\n",
    "        nome_modelo (str): Nome do modelo para salvar resultados\n",
    "        threshold (float): Limiar para classificação binária\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário com métricas de desempenho\n",
    "    \"\"\"\n",
    "    logger.info(f\"Avaliando modelo {nome_modelo} nos dados de teste\")\n",
    "\n",
    "    # Verificar se é necessário reshape para CNN ou modelos híbridos\n",
    "    if 'cnn' in nome_modelo.lower() or 'hibrido' in nome_modelo.lower():\n",
    "        if len(x_test.shape) == 2:\n",
    "            logger.info(\"Adicionando dimensão extra para dados CNN/híbridos\")\n",
    "            x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "\n",
    "    # Fazer predições\n",
    "    y_pred_prob = modelo.predict(x_test)\n",
    "    y_pred = (y_pred_prob > threshold).astype(int).flatten()\n",
    "    y_pred_prob = y_pred_prob.flatten()\n",
    "\n",
    "    # Calcular métricas\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_prob),\n",
    "        'average_precision': average_precision_score(y_test, y_pred_prob)\n",
    "    }\n",
    "\n",
    "    # Exibir métricas\n",
    "    logger.info(\"Métricas de desempenho:\")\n",
    "    for metric, value in metrics.items():\n",
    "        logger.info(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Salvar métricas em CSV\n",
    "    pd.DataFrame([metrics]).to_csv(f\"{RESULTS_DIR}/{nome_modelo}_metricas.csv\", index=False)\n",
    "\n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Relatório de classificação\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    pd.DataFrame(report).transpose().to_csv(f\"{RESULTS_DIR}/{nome_modelo}_classification_report.csv\")\n",
    "\n",
    "    # Visualizações\n",
    "    visualizar_resultados(y_test, y_pred, y_pred_prob, nome_modelo)\n",
    "\n",
    "    return metrics, y_pred, y_pred_prob\n",
    "\n",
    "\n",
    "def visualizar_resultados(y_true, y_pred, y_prob, nome_modelo):\n",
    "    \"\"\"\n",
    "    Cria visualizações para os resultados do modelo.\n",
    "\n",
    "    Args:\n",
    "        y_true (np.ndarray): Rótulos verdadeiros\n",
    "        y_pred (np.ndarray): Predições binárias\n",
    "        y_prob (np.ndarray): Probabilidades preditas\n",
    "        nome_modelo (str): Nome do modelo para salvar visualizações\n",
    "    \"\"\"\n",
    "    logger.info(f\"Gerando visualizações para resultados do modelo {nome_modelo}\")\n",
    "\n",
    "    # 1. Matriz de confusão\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Normalizar matriz de confusão\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Plotar matriz de confusão\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Matriz de Confusão - {nome_modelo}', fontsize=15)\n",
    "    plt.ylabel('Valor Real', fontsize=12)\n",
    "    plt.xlabel('Valor Predito', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_matriz_confusao.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Matriz de confusão normalizada\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Matriz de Confusão Normalizada - {nome_modelo}', fontsize=15)\n",
    "    plt.ylabel('Valor Real', fontsize=12)\n",
    "    plt.xlabel('Valor Predito', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_matriz_confusao_norm.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Curva ROC\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "    plt.title(f'Curva ROC - {nome_modelo}', fontsize=15)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_curva_roc.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Curva Precision-Recall\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    avg_precision = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AP = {avg_precision:.4f})')\n",
    "    plt.axhline(y=sum(y_true) / len(y_true), color='red', linestyle='--', label='Baseline')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title(f'Curva Precision-Recall - {nome_modelo}', fontsize=15)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_curva_precision_recall.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 4. Histograma de probabilidades\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Separar probabilidades por classe\n",
    "    prob_pos = y_prob[y_true == 1]\n",
    "    prob_neg = y_prob[y_true == 0]\n",
    "\n",
    "    plt.hist(prob_pos, bins=20, alpha=0.5, color='green', label='Classe Positiva (Diabetes)')\n",
    "    plt.hist(prob_neg, bins=20, alpha=0.5, color='red', label='Classe Negativa (Não Diabetes)')\n",
    "\n",
    "    plt.axvline(x=0.5, color='black', linestyle='--', label='Limiar (0.5)')\n",
    "    plt.xlabel('Probabilidade Predita', fontsize=12)\n",
    "    plt.ylabel('Contagem', fontsize=12)\n",
    "    plt.title(f'Distribuição de Probabilidades - {nome_modelo}', fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_distribuicao_probabilidades.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def visualizar_historico_treinamento(historico, nome_modelo):\n",
    "    \"\"\"\n",
    "    Visualiza o histórico de treinamento do modelo.\n",
    "\n",
    "    Args:\n",
    "        historico (tf.keras.callbacks.History): Histórico de treinamento\n",
    "        nome_modelo (str): Nome do modelo para salvar visualizações\n",
    "    \"\"\"\n",
    "    logger.info(f\"Visualizando histórico de treinamento do modelo {nome_modelo}\")\n",
    "\n",
    "    # 1. Curvas de perda (loss)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(historico['loss'], label='Treino', color='blue')\n",
    "    plt.plot(historico['val_loss'], label='Validação', color='orange')\n",
    "    plt.title(f'Curvas de Perda - {nome_modelo}', fontsize=15)\n",
    "    plt.xlabel('Época', fontsize=12)\n",
    "    plt.ylabel('Perda (Binary Crossentropy)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_curvas_perda.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Curvas de acurácia\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(historico['accuracy'], label='Treino', color='blue')\n",
    "    plt.plot(historico['val_accuracy'], label='Validação', color='orange')\n",
    "    plt.title(f'Curvas de Acurácia - {nome_modelo}', fontsize=15)\n",
    "    plt.xlabel('Época', fontsize=12)\n",
    "    plt.ylabel('Acurácia', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_curvas_acuracia.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Curvas de métricas adicionais\n",
    "    if 'precision' in historico.columns and 'recall' in historico.columns and 'auc' in historico.columns:\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(historico['precision'], label='Treino', color='blue')\n",
    "        plt.plot(historico['val_precision'], label='Validação', color='orange')\n",
    "        plt.title('Precisão', fontsize=13)\n",
    "        plt.xlabel('Época', fontsize=11)\n",
    "        plt.ylabel('Precisão', fontsize=11)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(historico['recall'], label='Treino', color='blue')\n",
    "        plt.plot(historico['val_recall'], label='Validação', color='orange')\n",
    "        plt.title('Recall', fontsize=13)\n",
    "        plt.xlabel('Época', fontsize=11)\n",
    "        plt.ylabel('Recall', fontsize=11)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(historico['auc'], label='Treino', color='blue')\n",
    "        plt.plot(historico['val_auc'], label='Validação', color='orange')\n",
    "        plt.title('AUC', fontsize=13)\n",
    "        plt.xlabel('Época', fontsize=11)\n",
    "        plt.ylabel('AUC', fontsize=11)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.suptitle(f'Métricas de Treinamento - {nome_modelo}', fontsize=16, y=1.05)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_curvas_metricas.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # 4. Curvas de aprendizado (Learning Curves)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Subplot para loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(historico['loss'], label='Treino', color='blue')\n",
    "    plt.plot(historico['val_loss'], label='Validação', color='orange')\n",
    "    plt.title('Perda (Loss)', fontsize=13)\n",
    "    plt.xlabel('Época', fontsize=11)\n",
    "    plt.ylabel('Perda', fontsize=11)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Subplot para accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(historico['accuracy'], label='Treino', color='blue')\n",
    "    plt.plot(historico['val_accuracy'], label='Validação', color='orange')\n",
    "    plt.title('Acurácia', fontsize=13)\n",
    "    plt.xlabel('Época', fontsize=11)\n",
    "    plt.ylabel('Acurácia', fontsize=11)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Calcular diferença entre treino e validação\n",
    "    if 'loss' in historico.columns and 'val_loss' in historico.columns:\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(historico['loss'] - historico['val_loss'], label='Diferença', color='green')\n",
    "        plt.axhline(y=0, color='red', linestyle='--')\n",
    "        plt.title('Diferença de Perda (Treino - Validação)', fontsize=13)\n",
    "        plt.xlabel('Época', fontsize=11)\n",
    "        plt.ylabel('Diferença', fontsize=11)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Calcular razão entre treino e validação\n",
    "    if 'accuracy' in historico.columns and 'val_accuracy' in historico.columns:\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(historico['accuracy'] / historico['val_accuracy'], label='Razão', color='purple')\n",
    "        plt.axhline(y=1, color='red', linestyle='--')\n",
    "        plt.title('Razão de Acurácia (Treino / Validação)', fontsize=13)\n",
    "        plt.xlabel('Época', fontsize=11)\n",
    "        plt.ylabel('Razão', fontsize=11)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'Curvas de Aprendizado - {nome_modelo}', fontsize=16, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_curvas_aprendizado.png\", dpi=300)\n",
    "    plt.close()"
   ],
   "id": "c9e03862ce76a35c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:01:22.779783Z",
     "start_time": "2025-07-02T23:01:22.763108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =====================================================================\n",
    "# FUNÇÕES PARA INTERPRETABILIDADE DE MODELOS\n",
    "# =====================================================================\n",
    "\n",
    "def analisar_importancia_variaveis(modelo, x_test, y_test, feature_names, nome_modelo, n_repeats=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Analisa a importância das variáveis no modelo usando cálculo manual de permutation importance com roc_auc.\n",
    "\n",
    "    Args:\n",
    "        modelo (tf.keras.Model): Modelo treinado\n",
    "        x_test (np.ndarray): Dados de teste\n",
    "        y_test (np.ndarray): Rótulos de teste\n",
    "        feature_names (list): Nomes das features\n",
    "        nome_modelo (str): Nome do modelo para salvar resultados\n",
    "        n_repeats (int): Número de repetições para permutação\n",
    "        random_state (int): Semente aleatória\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com importância das variáveis\n",
    "    \"\"\"\n",
    "    logger.info(f\"Analisando importância das variáveis para o modelo {nome_modelo} (cálculo manual)\")\n",
    "\n",
    "    # Determina se o modelo é CNN ou híbrido com base no nome\n",
    "    is_cnn_or_hybrid = 'cnn' in nome_modelo.lower() or 'hibrido' in nome_modelo.lower()\n",
    "\n",
    "    # Garante que x_test seja 2D para a lógica de permutação\n",
    "    x_test_2d = x_test\n",
    "    if is_cnn_or_hybrid and len(x_test.shape) == 3:\n",
    "        logger.info(\"Convertendo dados 3D para 2D para análise de importância\")\n",
    "        x_test_2d = x_test.reshape(x_test.shape[0], x_test.shape[1])\n",
    "\n",
    "    # Função para obter probabilidades do modelo Keras (considerando reshape)\n",
    "    def get_proba(x_input):\n",
    "        x_input_internal = x_input  # Usa cópia para evitar modificar original\n",
    "        if is_cnn_or_hybrid and len(x_input_internal.shape) == 2:\n",
    "            x_input_internal = x_input_internal.reshape(x_input_internal.shape[0], x_input_internal.shape[1], 1)\n",
    "        return modelo.predict(x_input_internal)[:, 0]  # Retorna prob da classe 1\n",
    "\n",
    "    # Calcula a pontuação base (AUC)\n",
    "    try:\n",
    "        baseline_proba = get_proba(x_test_2d)\n",
    "        baseline_score = roc_auc_score(y_test, baseline_proba)\n",
    "        logger.info(f\"Baseline ROC AUC score: {baseline_score:.4f}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao calcular baseline score para {nome_modelo}: {e}\")\n",
    "        return pd.DataFrame()  # Retorna DataFrame vazio em caso de falha\n",
    "\n",
    "    # Inicializa arrays para armazenar importâncias\n",
    "    importances_mean = np.zeros(x_test_2d.shape[1])\n",
    "    importances_std = np.zeros(x_test_2d.shape[1])\n",
    "    all_perm_scores = [[] for _ in range(x_test_2d.shape[1])]\n",
    "\n",
    "    # Itera sobre cada feature\n",
    "    logger.info(\"Calculando importância por permutação manual (pode levar algum tempo)\")\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    for col_idx in tqdm(range(x_test_2d.shape[1]), desc=f\"Permutando features - {nome_modelo}\"):\n",
    "        original_col = x_test_2d[:, col_idx].copy()\n",
    "        perm_scores = []\n",
    "\n",
    "        for _ in range(n_repeats):\n",
    "            # Permuta a coluna atual\n",
    "            x_test_permuted = x_test_2d.copy()\n",
    "            x_test_permuted[:, col_idx] = rng.permutation(original_col)\n",
    "\n",
    "            # Calcula a pontuação com a coluna permutada\n",
    "            try:\n",
    "                permuted_proba = get_proba(x_test_permuted)\n",
    "                perm_score = roc_auc_score(y_test, permuted_proba)\n",
    "                perm_scores.append(perm_score)\n",
    "                all_perm_scores[col_idx].append(perm_score)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Erro ao calcular score para feature {col_idx} permutada: {e}\")\n",
    "                perm_scores.append(np.nan)  # Adiciona NaN em caso de erro\n",
    "                all_perm_scores[col_idx].append(np.nan)\n",
    "\n",
    "        # Calcula a importância como a diferença para a baseline\n",
    "        valid_perm_scores = [s for s in perm_scores if not np.isnan(s)]\n",
    "        if valid_perm_scores:\n",
    "            importances_mean[col_idx] = baseline_score - np.mean(valid_perm_scores)\n",
    "            importances_std[col_idx] = np.std(valid_perm_scores)\n",
    "        else:\n",
    "            importances_mean[col_idx] = 0  # Define importância como 0 se todos os cálculos falharam\n",
    "            importances_std[col_idx] = 0\n",
    "\n",
    "    # Organizar resultados\n",
    "    importancia = pd.DataFrame({\n",
    "        'Feature': feature_names[:x_test_2d.shape[1]],  # Garantir que o número de features corresponda\n",
    "        'Importância': importances_mean,\n",
    "        'Desvio Padrão': importances_std\n",
    "    })\n",
    "\n",
    "    importancia = importancia.sort_values('Importância', ascending=False)\n",
    "\n",
    "    # Salvar resultados\n",
    "    importancia.to_csv(f\"{RESULTS_DIR}/{nome_modelo}_importancia_variaveis_manual.csv\", index=False)\n",
    "\n",
    "    # Visualizar importância das variáveis (top 15)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_features = importancia.head(15)\n",
    "    sns.barplot(x='Importância', y='Feature', data=top_features, palette='viridis', hue='Feature', legend=False)\n",
    "    plt.title(f'Top 15 Variáveis Mais Importantes (Manual) - {nome_modelo}', fontsize=15)\n",
    "    plt.xlabel('Importância (Queda no ROC AUC)', fontsize=12)\n",
    "    plt.ylabel('Variável', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_importancia_variaveis_manual.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Visualizar importância com barras de erro\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    top_features = importancia.head(10)\n",
    "    plt.errorbar(\n",
    "        x=top_features['Importância'],\n",
    "        y=range(len(top_features)),\n",
    "        xerr=top_features['Desvio Padrão'],  # Nota: std aqui é do score permutado, não da importância\n",
    "        fmt='o',\n",
    "        capsize=5,\n",
    "        color='blue'\n",
    "    )\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.title(f'Top 10 Variáveis com Desvio Padrão (Manual) - {nome_modelo}', fontsize=15)\n",
    "    plt.xlabel('Importância (Queda no ROC AUC)', fontsize=12)\n",
    "    plt.ylabel('Variável', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{RESULTS_DIR}/graficos/{nome_modelo}_importancia_variaveis_erro_manual.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return importancia\n",
    "\n",
    "\n",
    "def analisar_shap_values(modelo, x_test, feature_names, nome_modelo, max_display=10):\n",
    "    \"\"\"\n",
    "    Analisa a importância das variáveis usando SHAP values.\n",
    "\n",
    "    Args:\n",
    "        modelo (tf.keras.Model): Modelo treinado\n",
    "        x_test (np.ndarray): Dados de teste\n",
    "        feature_names (list): Nomes das features\n",
    "        nome_modelo (str): Nome do modelo para salvar resultados\n",
    "        max_display (int): Número máximo de features para exibir\n",
    "\n",
    "    Returns:\n",
    "        tuple: (explainer, shap_values)\n",
    "    \"\"\"\n",
    "    logger.info(f\"Analisando SHAP values para o modelo {nome_modelo}\")\n",
    "\n",
    "    # Verificar se é necessário reshape para CNN ou modelos híbridos\n",
    "    x_test_2d = x_test\n",
    "    if 'cnn' in nome_modelo.lower() or 'hibrido' in nome_modelo.lower():\n",
    "        if len(x_test.shape) == 3:\n",
    "            logger.info(\"Convertendo dados 3D para 2D para análise SHAP\")\n",
    "            x_test_2d = x_test.reshape(x_test.shape[0], x_test.shape[1])\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Usar uma amostra dos dados de teste para eficiência\n",
    "        sample_size = min(100, x_test_2d.shape[0])\n",
    "        x_sample = x_test_2d[:sample_size]\n",
    "\n",
    "        # Garantir que x_sample está 2D para o SHAP\n",
    "        if len(x_sample.shape) == 3 and x_sample.shape[2] == 1:\n",
    "            logger.info(\"Convertendo dados 3D para 2D para análise SHAP\")\n",
    "            x_sample_2d = x_sample.reshape(x_sample.shape[0], x_sample.shape[1])\n",
    "        else:\n",
    "            x_sample_2d = x_sample\n",
    "\n",
    "        # Calcular SHAP values\n",
    "        logger.info(\"Calculando SHAP values (pode levar algum tempo)\")\n",
    "        explainer = shap.Explainer(modelo, x_sample_2d)\n",
    "        shap_values = explainer.shap_values(x_sample_2d)\n",
    "\n",
    "        # Resumo das contribuições das features\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        shap.summary_plot(\n",
    "            shap_values,\n",
    "            x_sample_2d,\n",
    "            feature_names=feature_names[:x_test_2d.shape[1]],\n",
    "            max_display=max_display,\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f'SHAP Summary Plot - {nome_modelo}', fontsize=15)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{RESULTS_DIR}/graficos/shap/{nome_modelo}_shap_summary.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Gráfico de barras com importância média absoluta\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        shap.summary_plot(\n",
    "            shap_values,\n",
    "            x_sample_2d,\n",
    "            feature_names=feature_names[:x_test_2d.shape[1]],\n",
    "            plot_type='bar',\n",
    "            max_display=max_display,\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f'SHAP Feature Importance - {nome_modelo}', fontsize=15)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{RESULTS_DIR}/graficos/shap/{nome_modelo}_shap_importance.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Gráficos de dependência para as top 3 features\n",
    "        shap_df = pd.DataFrame(shap_values, columns=feature_names[:x_test_2d.shape[1]])\n",
    "        mean_abs_shap = np.abs(shap_df).mean().sort_values(ascending=False)\n",
    "        top_features = mean_abs_shap.index[:3].tolist()\n",
    "\n",
    "        for feature in top_features:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            feature_idx = list(feature_names[:x_test_2d.shape[1]]).index(feature)\n",
    "            shap.dependence_plot(\n",
    "                feature_idx,\n",
    "                shap_values,\n",
    "                x_sample_2d,\n",
    "                feature_names=feature_names[:x_test_2d.shape[1]],\n",
    "                show=False\n",
    "            )\n",
    "            plt.title(f'SHAP Dependence Plot - {feature} - {nome_modelo}', fontsize=15)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{RESULTS_DIR}/graficos/shap/{nome_modelo}_shap_dependence_{feature}.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        # Gráfico de força para algumas amostras individuais\n",
    "        for i in range(min(3, x_sample_2d.shape[0])):\n",
    "            plt.figure(figsize=(16, 6))\n",
    "            shap.force_plot(\n",
    "                explainer.expected_value,\n",
    "                shap_values[i],\n",
    "                x_sample_2d[i],\n",
    "                feature_names=feature_names[:x_test_2d.shape[1]],\n",
    "                matplotlib=True,\n",
    "                show=False\n",
    "            )\n",
    "            plt.title(f'SHAP Force Plot - Amostra {i + 1} - {nome_modelo}', fontsize=15)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{RESULTS_DIR}/graficos/shap/{nome_modelo}_shap_force_plot_sample_{i + 1}.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        return explainer, shap_values\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao calcular SHAP values: {e}\")\n",
    "        logger.info(\"Continuando com outras análises...\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def analisar_lime(modelo, x_train, x_test, y_test, feature_names, nome_modelo, num_amostras=3):\n",
    "    \"\"\"\n",
    "    Analisa o modelo usando LIME (Local Interpretable Model-agnostic Explanations).\n",
    "\n",
    "    Args:\n",
    "        modelo (tf.keras.Model): Modelo treinado\n",
    "        x_train (np.ndarray): Dados de treinamento\n",
    "        x_test (np.ndarray): Dados de teste\n",
    "        y_test (np.ndarray): Rótulos de teste\n",
    "        feature_names (list): Nomes das features\n",
    "        nome_modelo (str): Nome do modelo para salvar resultados\n",
    "        num_amostras (int): Número de amostras para explicar\n",
    "\n",
    "    Returns:\n",
    "        lime.lime_tabular.LimeTabularExplainer: Explainer LIME\n",
    "    \"\"\"\n",
    "    logger.info(f\"Analisando modelo {nome_modelo} usando LIME\")\n",
    "\n",
    "    # Verificar se é necessário reshape para CNN ou modelos híbridos\n",
    "    x_train_2d = x_train\n",
    "    x_test_2d = x_test\n",
    "    if 'cnn' in nome_modelo.lower() or 'hibrido' in nome_modelo.lower():\n",
    "        if len(x_train.shape) == 3:\n",
    "            logger.info(\"Convertendo dados 3D para 2D para análise LIME\")\n",
    "            x_train_2d = x_train.reshape(x_train.shape[0], x_train.shape[1])\n",
    "            x_test_2d = x_test.reshape(x_test.shape[0], x_test.shape[1])\n",
    "\n",
    "    # Função de predição para LIME\n",
    "    def predict_func(x):\n",
    "        # Garantir que X seja um array numpy e tenha o formato correto\n",
    "        if not isinstance(x, np.ndarray):\n",
    "            x = np.array(x)\n",
    "\n",
    "        # Garantir que X seja 2D\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "\n",
    "        # Garantir que X tenha o número correto de features\n",
    "        if x.shape[1] != x_test_2d.shape[1]:\n",
    "            logger.warning(f\"Shape mismatch: esperado {x_test_2d.shape[1]} features, recebido {x.shape[1]}\")\n",
    "            return np.array([[0.5, 0.5]] * x.shape[0])\n",
    "\n",
    "        try:\n",
    "            if 'cnn' in nome_modelo.lower() or 'hibrido' in nome_modelo.lower():\n",
    "                x_reshaped = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "                proba = modelo.predict(x_reshaped, verbose=0)\n",
    "            else:\n",
    "                proba = modelo.predict(x, verbose=0)\n",
    "\n",
    "            # Garante que proba é 1D para a classe positiva\n",
    "            proba_pos = proba.reshape(-1)\n",
    "\n",
    "            # Clamp probabilidades para evitar valores extremos\n",
    "            proba_pos = np.clip(proba_pos, 1e-7, 1 - 1e-7)\n",
    "\n",
    "            # Retorna as probabilidades para as duas classes\n",
    "            proba_neg = 1 - proba_pos\n",
    "            return np.column_stack([proba_neg, proba_pos])\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Erro na predição LIME: {e}. Retornando probabilidades padrão.\")\n",
    "            # Retornar probabilidades padrão em caso de erro\n",
    "            return np.array([[0.5, 0.5]] * x.shape[0])\n",
    "\n",
    "    try:\n",
    "        # Criar explainer LIME\n",
    "        logger.info(\"Criando LIME explainer\")\n",
    "        explainer = lime_tabular.LimeTabularExplainer(\n",
    "            x_train_2d,\n",
    "            feature_names=feature_names[:x_test_2d.shape[1]],\n",
    "            class_names=['Não Diabetes', 'Diabetes'],\n",
    "            mode='classification'\n",
    "        )\n",
    "\n",
    "        # Selecionar amostras para explicar\n",
    "        amostras_para_explicar = np.random.choice(x_test.shape[0], size=num_amostras, replace=False)\n",
    "\n",
    "        for i in amostras_para_explicar:\n",
    "            logger.info(f\"Explicando amostra {i}\")\n",
    "\n",
    "            # Gerar explicação\n",
    "            exp = explainer.explain_instance(\n",
    "                x_test_2d[i],\n",
    "                predict_func,\n",
    "                num_features=10\n",
    "            )\n",
    "\n",
    "            # Visualizar explicação\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            exp.as_pyplot_figure()\n",
    "            plt.title(f'Explicação LIME - Amostra {i} - {nome_modelo}', fontsize=15)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{RESULTS_DIR}/graficos/lime/{nome_modelo}_lime_amostra_{i}.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        return explainer\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao gerar explicações LIME: {e}\")\n",
    "        logger.info(\"Continuando com outras análises...\")\n",
    "        return None\n"
   ],
   "id": "f8748e0b4e0c49bf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:02:22.541046Z",
     "start_time": "2025-07-02T23:01:22.817356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Carregar e analisar dados\n",
    "df = carregar_dados(\"diabetes_prediction_dataset.csv\")\n",
    "analisar_dados(df)\n",
    "\n",
    "# 2. Pré-processamento dos dados\n",
    "x_train, X_val, x_test, y_train, y_val, y_test, pre_processador, feature_names = pre_processar_dados(\n",
    "    df,\n",
    "    metodo_normalizacao='standard',\n",
    "    metodo_balanceamento='smote',\n",
    "    tratar_outliers=True\n",
    ")\n",
    "\n",
    "# Reshape para CNN\n",
    "x_train_cnn = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "X_test_cnn = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n"
   ],
   "id": "7528c487bd514aef",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:16:18.092880Z",
     "start_time": "2025-07-02T23:02:22.600236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Treinar modelos clássicos\n",
    "resultados_classicos = treinar_modelos_classicos(x_train, y_train, x_test, y_test, feature_names)"
   ],
   "id": "d9397016a0ef8788",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2741            9.67s\n",
      "         2           1.1805            9.87s\n",
      "         3           1.1027            9.82s\n",
      "         4           1.0288            9.99s\n",
      "         5           0.9695            9.62s\n",
      "         6           0.9184            9.51s\n",
      "         7           0.8675            9.47s\n",
      "         8           0.8280            9.28s\n",
      "         9           0.7879            9.22s\n",
      "        10           0.7556            9.10s\n",
      "        20           0.5443            8.31s\n",
      "        30           0.4510            7.28s\n",
      "        40           0.3936            6.28s\n",
      "        50           0.3580            5.27s\n",
      "        60           0.3318            4.23s\n",
      "        70           0.3155            3.18s\n",
      "        80           0.2878            2.12s\n",
      "        90           0.2610            1.06s\n",
      "       100           0.2469            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabcneto/.virtualenvs/codigo/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [20:02:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\", \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 73186, number of negative: 73185\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1026\n",
      "[LightGBM] [Info] Number of data points in the train set: 146371, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000014\n",
      "[LightGBM] [Info] Start training from score 0.000014\n",
      "[LibSVM]...................................\n",
      "Warning: using -h 0 may be faster\n",
      "*...*...*\n",
      "optimization finished, #iter = 41095\n",
      "obj = -26358.180764, rho = 1.801914\n",
      "nSV = 27362, nBSV = 19184\n",
      "Total nSV = 27362\n",
      "..................................\n",
      "Warning: using -h 0 may be faster\n",
      "*....*...*\n",
      "optimization finished, #iter = 40594\n",
      "obj = -26042.176836, rho = 1.858559\n",
      "nSV = 27046, nBSV = 19183\n",
      "Total nSV = 27046\n",
      "..................................\n",
      "Warning: using -h 0 may be faster\n",
      "*....*...*\n",
      "optimization finished, #iter = 40614\n",
      "obj = -26182.740139, rho = 1.854406\n",
      "nSV = 27184, nBSV = 19289\n",
      "Total nSV = 27184\n",
      "..................................\n",
      "Warning: using -h 0 may be faster\n",
      "*....*.\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 38950\n",
      "obj = -26307.529649, rho = 1.856786\n",
      "nSV = 27325, nBSV = 19874\n",
      "Total nSV = 27325\n",
      "...................................\n",
      "Warning: using -h 0 may be faster\n",
      "*....*..*.*\n",
      "optimization finished, #iter = 40227\n",
      "obj = -26268.183797, rho = 1.815954\n",
      "nSV = 27280, nBSV = 19774\n",
      "Total nSV = 27280\n",
      "Line search fails in two-class probability estimates\n",
      ".............................................\n",
      "Warning: using -h 0 may be faster\n",
      "*.....*....\n",
      "Warning: using -h 0 may be faster\n",
      "*.\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 55071\n",
      "obj = -32552.061090, rho = -1.943248\n",
      "nSV = 33738, nBSV = 25210\n",
      "Total nSV = 33738\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:19:47.889646Z",
     "start_time": "2025-07-02T23:16:18.127925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Treinar e avaliar modelo MLP\n",
    "logger.info(\"Treinando modelo MLP\")\n",
    "modelo_mlp = criar_modelo_mlp(\n",
    "    input_shape=(x_train.shape[1],),\n",
    "    camadas=[128, 64, 32],\n",
    "    activations=['relu', 'relu', 'relu'],\n",
    "    dropout_rates=[0.3, 0.3, 0.3],\n",
    "    regularization=0.001,\n",
    "    learning_rate=0.001,\n",
    "    batch_norm=True\n",
    ")\n",
    "\n",
    "treinar_modelo(\n",
    "    modelo_mlp, x_train, y_train, X_val, y_val,\n",
    "    nome_modelo=\"mlp\",\n",
    "    batch_size=128,\n",
    "    epochs=100\n",
    ")"
   ],
   "id": "15f9bfa5a21ca7e7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751498178.603338  126490 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │         \u001B[38;5;34m1,664\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_1                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_2                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_3                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_1                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_2                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_3                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m12,929\u001B[0m (50.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,929</span> (50.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m12,481\u001B[0m (48.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,481</span> (48.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m448\u001B[0m (1.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751498181.563279  134294 service.cc:152] XLA service 0x7f9a4801b470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1751498181.563368  134294 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-02 20:16:21.625913: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1751498181.875123  134294 cuda_dnn.cc:529] Loaded cuDNN version 91001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m   1/1144\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m56:16\u001B[0m 3s/step - accuracy: 0.4766 - loss: 0.9443 - recall: 0.6508"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1751498183.224670  134294 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8566 - loss: 0.4054 - recall: 0.8602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 20:16:31.338978: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_103', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "/home/jabcneto/.virtualenvs/codigo/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:302: UserWarning: Can save best model only with val_auc available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 8ms/step - accuracy: 0.8567 - loss: 0.4053 - recall: 0.8603 - val_accuracy: 0.9035 - val_loss: 0.2347 - val_recall: 0.9436 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step - accuracy: 0.8941 - loss: 0.2451 - recall: 0.9213 - val_accuracy: 0.9041 - val_loss: 0.2159 - val_recall: 0.9423 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8947 - loss: 0.2328 - recall: 0.9213 - val_accuracy: 0.9041 - val_loss: 0.2121 - val_recall: 0.9377 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8950 - loss: 0.2300 - recall: 0.9200 - val_accuracy: 0.9033 - val_loss: 0.2108 - val_recall: 0.9348 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8939 - loss: 0.2275 - recall: 0.9215 - val_accuracy: 0.9009 - val_loss: 0.2123 - val_recall: 0.9408 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8951 - loss: 0.2272 - recall: 0.9201 - val_accuracy: 0.9017 - val_loss: 0.2113 - val_recall: 0.9355 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8953 - loss: 0.2255 - recall: 0.9206 - val_accuracy: 0.9012 - val_loss: 0.2095 - val_recall: 0.9438 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8962 - loss: 0.2251 - recall: 0.9217 - val_accuracy: 0.9019 - val_loss: 0.2132 - val_recall: 0.9469 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8954 - loss: 0.2251 - recall: 0.9215 - val_accuracy: 0.9027 - val_loss: 0.2112 - val_recall: 0.9370 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8958 - loss: 0.2253 - recall: 0.9222 - val_accuracy: 0.9017 - val_loss: 0.2078 - val_recall: 0.9305 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8959 - loss: 0.2241 - recall: 0.9236 - val_accuracy: 0.9033 - val_loss: 0.2088 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8965 - loss: 0.2246 - recall: 0.9251 - val_accuracy: 0.9031 - val_loss: 0.2081 - val_recall: 0.9432 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8964 - loss: 0.2235 - recall: 0.9229 - val_accuracy: 0.9042 - val_loss: 0.2074 - val_recall: 0.9436 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8965 - loss: 0.2231 - recall: 0.9218 - val_accuracy: 0.9030 - val_loss: 0.2074 - val_recall: 0.9335 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8968 - loss: 0.2220 - recall: 0.9248 - val_accuracy: 0.9033 - val_loss: 0.2057 - val_recall: 0.9353 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8964 - loss: 0.2216 - recall: 0.9248 - val_accuracy: 0.9038 - val_loss: 0.2068 - val_recall: 0.9414 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8961 - loss: 0.2212 - recall: 0.9238 - val_accuracy: 0.9023 - val_loss: 0.2065 - val_recall: 0.9331 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8968 - loss: 0.2221 - recall: 0.9252 - val_accuracy: 0.9026 - val_loss: 0.2047 - val_recall: 0.9432 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8969 - loss: 0.2227 - recall: 0.9261 - val_accuracy: 0.9039 - val_loss: 0.2055 - val_recall: 0.9436 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8961 - loss: 0.2222 - recall: 0.9223 - val_accuracy: 0.9023 - val_loss: 0.2051 - val_recall: 0.9379 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8960 - loss: 0.2220 - recall: 0.9269 - val_accuracy: 0.9026 - val_loss: 0.2051 - val_recall: 0.9390 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8969 - loss: 0.2210 - recall: 0.9273 - val_accuracy: 0.9046 - val_loss: 0.2040 - val_recall: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8968 - loss: 0.2216 - recall: 0.9248 - val_accuracy: 0.9039 - val_loss: 0.2041 - val_recall: 0.9383 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8964 - loss: 0.2212 - recall: 0.9265 - val_accuracy: 0.9044 - val_loss: 0.2038 - val_recall: 0.9427 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8968 - loss: 0.2211 - recall: 0.9268 - val_accuracy: 0.9011 - val_loss: 0.2058 - val_recall: 0.9388 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8960 - loss: 0.2213 - recall: 0.9256 - val_accuracy: 0.9035 - val_loss: 0.2041 - val_recall: 0.9379 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8967 - loss: 0.2212 - recall: 0.9284 - val_accuracy: 0.9030 - val_loss: 0.2051 - val_recall: 0.9495 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8964 - loss: 0.2220 - recall: 0.9264 - val_accuracy: 0.9028 - val_loss: 0.2068 - val_recall: 0.9456 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001B[1m1130/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8967 - loss: 0.2203 - recall: 0.9257\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8967 - loss: 0.2203 - recall: 0.9257 - val_accuracy: 0.9031 - val_loss: 0.2059 - val_recall: 0.9383 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8972 - loss: 0.2168 - recall: 0.9249 - val_accuracy: 0.9019 - val_loss: 0.2021 - val_recall: 0.9353 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8983 - loss: 0.2143 - recall: 0.9296 - val_accuracy: 0.9041 - val_loss: 0.2004 - val_recall: 0.9342 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8976 - loss: 0.2155 - recall: 0.9260 - val_accuracy: 0.9030 - val_loss: 0.2012 - val_recall: 0.9388 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8989 - loss: 0.2143 - recall: 0.9283 - val_accuracy: 0.9040 - val_loss: 0.2009 - val_recall: 0.9368 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.2138 - recall: 0.9273 - val_accuracy: 0.9024 - val_loss: 0.2008 - val_recall: 0.9298 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8983 - loss: 0.2138 - recall: 0.9271 - val_accuracy: 0.9033 - val_loss: 0.1998 - val_recall: 0.9355 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8983 - loss: 0.2142 - recall: 0.9270 - val_accuracy: 0.9035 - val_loss: 0.1990 - val_recall: 0.9333 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8987 - loss: 0.2131 - recall: 0.9266 - val_accuracy: 0.9036 - val_loss: 0.2006 - val_recall: 0.9429 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.2136 - recall: 0.9286 - val_accuracy: 0.9025 - val_loss: 0.1992 - val_recall: 0.9344 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8977 - loss: 0.2134 - recall: 0.9277 - val_accuracy: 0.9036 - val_loss: 0.1992 - val_recall: 0.9401 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8985 - loss: 0.2130 - recall: 0.9295 - val_accuracy: 0.9033 - val_loss: 0.1998 - val_recall: 0.9362 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8990 - loss: 0.2132 - recall: 0.9289 - val_accuracy: 0.9040 - val_loss: 0.1982 - val_recall: 0.9386 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.2131 - recall: 0.9297 - val_accuracy: 0.9058 - val_loss: 0.1984 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8987 - loss: 0.2132 - recall: 0.9301 - val_accuracy: 0.9048 - val_loss: 0.1997 - val_recall: 0.9421 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8985 - loss: 0.2139 - recall: 0.9285 - val_accuracy: 0.9029 - val_loss: 0.1993 - val_recall: 0.9397 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8990 - loss: 0.2123 - recall: 0.9310 - val_accuracy: 0.9035 - val_loss: 0.1986 - val_recall: 0.9353 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001B[1m1137/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8993 - loss: 0.2121 - recall: 0.9283\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8993 - loss: 0.2121 - recall: 0.9283 - val_accuracy: 0.9041 - val_loss: 0.1988 - val_recall: 0.9386 - learning_rate: 5.0000e-04\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:25:39.010718Z",
     "start_time": "2025-07-02T23:19:47.927706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Treinar e avaliar modelo CNN\n",
    "logger.info(\"Treinando modelo CNN\")\n",
    "modelo_cnn = criar_modelo_cnn(\n",
    "    input_shape=(x_train.shape[1], 1),\n",
    "    filtros=[64, 32, 16],\n",
    "    kernel_sizes=[3, 3, 3],\n",
    "    ativacoes=['relu', 'relu', 'relu'],\n",
    "    dropout_rates=[0.3, 0.3, 0.3],\n",
    "    pool_sizes=[2, 2, 2],\n",
    "    regularizacao=0.001,\n",
    "    learning_rate=0.005,\n",
    "    batch_norm=True\n",
    ")\n",
    "\n",
    "treinar_modelo(\n",
    "    modelo_cnn, x_train_cnn, y_train, X_val_cnn, y_val,\n",
    "    nome_modelo=\"cnn\",\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    ")"
   ],
   "id": "52add393f9d06682",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_1 (\u001B[38;5;33mConv1D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │           \u001B[38;5;34m256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_1                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_1 (\u001B[38;5;33mMaxPooling1D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m64\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m64\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_2 (\u001B[38;5;33mConv1D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │         \u001B[38;5;34m6,176\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_2                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_2 (\u001B[38;5;33mMaxPooling1D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_3 (\u001B[38;5;33mConv1D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │         \u001B[38;5;34m1,552\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_3                    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │            \u001B[38;5;34m64\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001B[38;5;33mActivation\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_3 (\u001B[38;5;33mMaxPooling1D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m1,056\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense (\u001B[38;5;33mActivation\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense (\u001B[38;5;33mDropout\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_1                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_2                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_3                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m9,649\u001B[0m (37.69 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,649</span> (37.69 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m9,361\u001B[0m (36.57 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,361</span> (36.57 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m288\u001B[0m (1.12 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 7ms/step - accuracy: 0.8643 - loss: 0.3457 - recall: 0.8749 - val_accuracy: 0.8948 - val_loss: 0.2483 - val_recall: 0.9569 - learning_rate: 0.0050\n",
      "Epoch 2/100\n",
      "\u001B[1m   1/1144\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m31s\u001B[0m 28ms/step - accuracy: 0.9062 - loss: 0.2352 - recall: 0.9524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabcneto/.virtualenvs/codigo/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:302: UserWarning: Can save best model only with val_auc available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 4ms/step - accuracy: 0.8849 - loss: 0.2720 - recall: 0.9152 - val_accuracy: 0.8975 - val_loss: 0.2409 - val_recall: 0.9379 - learning_rate: 0.0050\n",
      "Epoch 3/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8867 - loss: 0.2682 - recall: 0.9170 - val_accuracy: 0.8966 - val_loss: 0.2431 - val_recall: 0.9038 - learning_rate: 0.0050\n",
      "Epoch 4/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8857 - loss: 0.2680 - recall: 0.9155 - val_accuracy: 0.8935 - val_loss: 0.2509 - val_recall: 0.9639 - learning_rate: 0.0050\n",
      "Epoch 5/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8874 - loss: 0.2654 - recall: 0.9158 - val_accuracy: 0.8979 - val_loss: 0.2429 - val_recall: 0.9556 - learning_rate: 0.0050\n",
      "Epoch 6/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8874 - loss: 0.2674 - recall: 0.9184 - val_accuracy: 0.8987 - val_loss: 0.2349 - val_recall: 0.9558 - learning_rate: 0.0050\n",
      "Epoch 7/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8867 - loss: 0.2643 - recall: 0.9192 - val_accuracy: 0.8990 - val_loss: 0.2357 - val_recall: 0.9383 - learning_rate: 0.0050\n",
      "Epoch 8/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8867 - loss: 0.2649 - recall: 0.9178 - val_accuracy: 0.8994 - val_loss: 0.2394 - val_recall: 0.9340 - learning_rate: 0.0050\n",
      "Epoch 9/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8879 - loss: 0.2662 - recall: 0.9198 - val_accuracy: 0.8983 - val_loss: 0.2396 - val_recall: 0.9062 - learning_rate: 0.0050\n",
      "Epoch 10/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8866 - loss: 0.2671 - recall: 0.9200 - val_accuracy: 0.8993 - val_loss: 0.2368 - val_recall: 0.9305 - learning_rate: 0.0050\n",
      "Epoch 11/100\n",
      "\u001B[1m1139/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8864 - loss: 0.2660 - recall: 0.9193\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8864 - loss: 0.2660 - recall: 0.9193 - val_accuracy: 0.8982 - val_loss: 0.2444 - val_recall: 0.9453 - learning_rate: 0.0050\n",
      "Epoch 12/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8920 - loss: 0.2492 - recall: 0.9258 - val_accuracy: 0.9000 - val_loss: 0.2237 - val_recall: 0.9353 - learning_rate: 0.0025\n",
      "Epoch 13/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 5ms/step - accuracy: 0.8924 - loss: 0.2442 - recall: 0.9239 - val_accuracy: 0.9007 - val_loss: 0.2198 - val_recall: 0.9447 - learning_rate: 0.0025\n",
      "Epoch 14/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8910 - loss: 0.2435 - recall: 0.9243 - val_accuracy: 0.8990 - val_loss: 0.2283 - val_recall: 0.9244 - learning_rate: 0.0025\n",
      "Epoch 15/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8910 - loss: 0.2447 - recall: 0.9204 - val_accuracy: 0.8992 - val_loss: 0.2236 - val_recall: 0.9362 - learning_rate: 0.0025\n",
      "Epoch 16/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8925 - loss: 0.2433 - recall: 0.9239 - val_accuracy: 0.9024 - val_loss: 0.2265 - val_recall: 0.9517 - learning_rate: 0.0025\n",
      "Epoch 17/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.8905 - loss: 0.2432 - recall: 0.9234 - val_accuracy: 0.9005 - val_loss: 0.2269 - val_recall: 0.9491 - learning_rate: 0.0025\n",
      "Epoch 18/100\n",
      "\u001B[1m1135/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8918 - loss: 0.2425 - recall: 0.9223\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8918 - loss: 0.2424 - recall: 0.9223 - val_accuracy: 0.9011 - val_loss: 0.2221 - val_recall: 0.9436 - learning_rate: 0.0025\n",
      "Epoch 19/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8945 - loss: 0.2343 - recall: 0.9278 - val_accuracy: 0.9014 - val_loss: 0.2158 - val_recall: 0.9303 - learning_rate: 0.0012\n",
      "Epoch 20/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8965 - loss: 0.2274 - recall: 0.9279 - val_accuracy: 0.9022 - val_loss: 0.2133 - val_recall: 0.9366 - learning_rate: 0.0012\n",
      "Epoch 21/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8955 - loss: 0.2280 - recall: 0.9256 - val_accuracy: 0.9029 - val_loss: 0.2085 - val_recall: 0.9488 - learning_rate: 0.0012\n",
      "Epoch 22/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8955 - loss: 0.2272 - recall: 0.9294 - val_accuracy: 0.9009 - val_loss: 0.2129 - val_recall: 0.9357 - learning_rate: 0.0012\n",
      "Epoch 23/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8964 - loss: 0.2268 - recall: 0.9281 - val_accuracy: 0.9016 - val_loss: 0.2104 - val_recall: 0.9403 - learning_rate: 0.0012\n",
      "Epoch 24/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8960 - loss: 0.2269 - recall: 0.9258 - val_accuracy: 0.9023 - val_loss: 0.2144 - val_recall: 0.9506 - learning_rate: 0.0012\n",
      "Epoch 25/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8968 - loss: 0.2274 - recall: 0.9288 - val_accuracy: 0.9025 - val_loss: 0.2087 - val_recall: 0.9456 - learning_rate: 0.0012\n",
      "Epoch 26/100\n",
      "\u001B[1m1134/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8963 - loss: 0.2274 - recall: 0.9284\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8963 - loss: 0.2274 - recall: 0.9284 - val_accuracy: 0.9035 - val_loss: 0.2117 - val_recall: 0.9502 - learning_rate: 0.0012\n",
      "Epoch 27/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8984 - loss: 0.2223 - recall: 0.9297 - val_accuracy: 0.9034 - val_loss: 0.2049 - val_recall: 0.9475 - learning_rate: 6.2500e-04\n",
      "Epoch 28/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8974 - loss: 0.2197 - recall: 0.9262 - val_accuracy: 0.9027 - val_loss: 0.2074 - val_recall: 0.9348 - learning_rate: 6.2500e-04\n",
      "Epoch 29/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8973 - loss: 0.2177 - recall: 0.9294 - val_accuracy: 0.9034 - val_loss: 0.2035 - val_recall: 0.9425 - learning_rate: 6.2500e-04\n",
      "Epoch 30/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8991 - loss: 0.2158 - recall: 0.9294 - val_accuracy: 0.9038 - val_loss: 0.2069 - val_recall: 0.9519 - learning_rate: 6.2500e-04\n",
      "Epoch 31/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8984 - loss: 0.2157 - recall: 0.9294 - val_accuracy: 0.9030 - val_loss: 0.2028 - val_recall: 0.9482 - learning_rate: 6.2500e-04\n",
      "Epoch 32/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8978 - loss: 0.2163 - recall: 0.9278 - val_accuracy: 0.9035 - val_loss: 0.2052 - val_recall: 0.9504 - learning_rate: 6.2500e-04\n",
      "Epoch 33/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8986 - loss: 0.2165 - recall: 0.9282 - val_accuracy: 0.9031 - val_loss: 0.2026 - val_recall: 0.9386 - learning_rate: 6.2500e-04\n",
      "Epoch 34/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8985 - loss: 0.2163 - recall: 0.9298 - val_accuracy: 0.9024 - val_loss: 0.2035 - val_recall: 0.9405 - learning_rate: 6.2500e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8973 - loss: 0.2169 - recall: 0.9270 - val_accuracy: 0.9031 - val_loss: 0.2036 - val_recall: 0.9351 - learning_rate: 6.2500e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8987 - loss: 0.2161 - recall: 0.9261 - val_accuracy: 0.9035 - val_loss: 0.2034 - val_recall: 0.9357 - learning_rate: 6.2500e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8979 - loss: 0.2158 - recall: 0.9279 - val_accuracy: 0.9035 - val_loss: 0.2011 - val_recall: 0.9434 - learning_rate: 6.2500e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8985 - loss: 0.2154 - recall: 0.9292 - val_accuracy: 0.9024 - val_loss: 0.2016 - val_recall: 0.9416 - learning_rate: 6.2500e-04\n",
      "Epoch 39/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8990 - loss: 0.2162 - recall: 0.9274 - val_accuracy: 0.9031 - val_loss: 0.2033 - val_recall: 0.9526 - learning_rate: 6.2500e-04\n",
      "Epoch 40/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8985 - loss: 0.2159 - recall: 0.9271 - val_accuracy: 0.9041 - val_loss: 0.2016 - val_recall: 0.9408 - learning_rate: 6.2500e-04\n",
      "Epoch 41/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8983 - loss: 0.2153 - recall: 0.9297 - val_accuracy: 0.9040 - val_loss: 0.2012 - val_recall: 0.9471 - learning_rate: 6.2500e-04\n",
      "Epoch 42/100\n",
      "\u001B[1m1142/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.2156 - recall: 0.9288\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.2156 - recall: 0.9288 - val_accuracy: 0.9034 - val_loss: 0.2046 - val_recall: 0.9379 - learning_rate: 6.2500e-04\n",
      "Epoch 43/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8998 - loss: 0.2124 - recall: 0.9281 - val_accuracy: 0.9030 - val_loss: 0.1994 - val_recall: 0.9348 - learning_rate: 3.1250e-04\n",
      "Epoch 44/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.8997 - loss: 0.2108 - recall: 0.9298 - val_accuracy: 0.9028 - val_loss: 0.2006 - val_recall: 0.9403 - learning_rate: 3.1250e-04\n",
      "Epoch 45/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8992 - loss: 0.2105 - recall: 0.9281 - val_accuracy: 0.9035 - val_loss: 0.1990 - val_recall: 0.9340 - learning_rate: 3.1250e-04\n",
      "Epoch 46/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.9001 - loss: 0.2097 - recall: 0.9282 - val_accuracy: 0.9037 - val_loss: 0.1996 - val_recall: 0.9346 - learning_rate: 3.1250e-04\n",
      "Epoch 47/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.9005 - loss: 0.2091 - recall: 0.9299 - val_accuracy: 0.9027 - val_loss: 0.1976 - val_recall: 0.9333 - learning_rate: 3.1250e-04\n",
      "Epoch 48/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.9000 - loss: 0.2089 - recall: 0.9294 - val_accuracy: 0.9046 - val_loss: 0.1982 - val_recall: 0.9423 - learning_rate: 3.1250e-04\n",
      "Epoch 49/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8993 - loss: 0.2085 - recall: 0.9292 - val_accuracy: 0.9046 - val_loss: 0.1978 - val_recall: 0.9418 - learning_rate: 3.1250e-04\n",
      "Epoch 50/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.9006 - loss: 0.2082 - recall: 0.9305 - val_accuracy: 0.9023 - val_loss: 0.1991 - val_recall: 0.9324 - learning_rate: 3.1250e-04\n",
      "Epoch 51/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9001 - loss: 0.2088 - recall: 0.9300 - val_accuracy: 0.9034 - val_loss: 0.1970 - val_recall: 0.9322 - learning_rate: 3.1250e-04\n",
      "Epoch 52/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8996 - loss: 0.2082 - recall: 0.9284 - val_accuracy: 0.9030 - val_loss: 0.1970 - val_recall: 0.9397 - learning_rate: 3.1250e-04\n",
      "Epoch 53/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8996 - loss: 0.2087 - recall: 0.9288 - val_accuracy: 0.9049 - val_loss: 0.1972 - val_recall: 0.9359 - learning_rate: 3.1250e-04\n",
      "Epoch 54/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8999 - loss: 0.2075 - recall: 0.9300 - val_accuracy: 0.9039 - val_loss: 0.1969 - val_recall: 0.9432 - learning_rate: 3.1250e-04\n",
      "Epoch 55/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8994 - loss: 0.2075 - recall: 0.9276 - val_accuracy: 0.9036 - val_loss: 0.1966 - val_recall: 0.9418 - learning_rate: 3.1250e-04\n",
      "Epoch 56/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9001 - loss: 0.2082 - recall: 0.9286 - val_accuracy: 0.9034 - val_loss: 0.1964 - val_recall: 0.9344 - learning_rate: 3.1250e-04\n",
      "Epoch 57/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9006 - loss: 0.2097 - recall: 0.9296 - val_accuracy: 0.9039 - val_loss: 0.1959 - val_recall: 0.9427 - learning_rate: 3.1250e-04\n",
      "Epoch 58/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9004 - loss: 0.2069 - recall: 0.9261 - val_accuracy: 0.9042 - val_loss: 0.1965 - val_recall: 0.9351 - learning_rate: 3.1250e-04\n",
      "Epoch 59/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8994 - loss: 0.2072 - recall: 0.9277 - val_accuracy: 0.9042 - val_loss: 0.1960 - val_recall: 0.9390 - learning_rate: 3.1250e-04\n",
      "Epoch 60/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8999 - loss: 0.2075 - recall: 0.9285 - val_accuracy: 0.9036 - val_loss: 0.1976 - val_recall: 0.9359 - learning_rate: 3.1250e-04\n",
      "Epoch 61/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9001 - loss: 0.2077 - recall: 0.9287 - val_accuracy: 0.9035 - val_loss: 0.1973 - val_recall: 0.9416 - learning_rate: 3.1250e-04\n",
      "Epoch 62/100\n",
      "\u001B[1m1138/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8991 - loss: 0.2085 - recall: 0.9279\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.8991 - loss: 0.2085 - recall: 0.9279 - val_accuracy: 0.9035 - val_loss: 0.1961 - val_recall: 0.9386 - learning_rate: 3.1250e-04\n",
      "Epoch 63/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9009 - loss: 0.2060 - recall: 0.9301 - val_accuracy: 0.9034 - val_loss: 0.1966 - val_recall: 0.9307 - learning_rate: 1.5625e-04\n",
      "Epoch 64/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 5ms/step - accuracy: 0.9015 - loss: 0.2051 - recall: 0.9298 - val_accuracy: 0.9052 - val_loss: 0.1961 - val_recall: 0.9364 - learning_rate: 1.5625e-04\n",
      "Epoch 65/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9023 - loss: 0.2042 - recall: 0.9290 - val_accuracy: 0.9040 - val_loss: 0.1966 - val_recall: 0.9276 - learning_rate: 1.5625e-04\n",
      "Epoch 66/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 4ms/step - accuracy: 0.9008 - loss: 0.2041 - recall: 0.9300 - val_accuracy: 0.9030 - val_loss: 0.1958 - val_recall: 0.9314 - learning_rate: 1.5625e-04\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:37:19.092636Z",
     "start_time": "2025-07-02T23:25:39.031683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. Treinar e avaliar modelo híbrido\n",
    "logger.info(\"Treinando modelo híbrido CNN-LSTM\")\n",
    "modelo_hibrido = criar_modelo_hibrido(\n",
    "    input_shape=(x_train.shape[1], 1),\n",
    "    filtros_cnn=[64, 32, 16],\n",
    "    kernel_sizes=[3, 3, 3],\n",
    "    unidades_lstm=32,\n",
    "    unidades_densas=[64, 32, 16],\n",
    "    ativacoes=['relu', 'relu', 'relu'],\n",
    "    dropout_rates=[0.3, 0.3, 0.3],\n",
    "    regularizacao=0.001,\n",
    "    learning_rate=0.001,\n",
    "    batch_norm=True\n",
    ")\n",
    "\n",
    "treinar_modelo(\n",
    "    modelo_hibrido, x_train_cnn, y_train, X_val_cnn, y_val,\n",
    "    nome_modelo=\"hibrido\",\n",
    "    batch_size=128,\n",
    "    epochs=100\n",
    ")"
   ],
   "id": "cd6dd53c7f234d0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_68\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_68\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m1\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_1 (\u001B[38;5;33mConv1D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │           \u001B[38;5;34m256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_conv_1               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_conv_1 (\u001B[38;5;33mActivation\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m12\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_1 (\u001B[38;5;33mMaxPooling1D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m64\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_2 (\u001B[38;5;33mConv1D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │         \u001B[38;5;34m6,176\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_conv_2               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_conv_2 (\u001B[38;5;33mActivation\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_2 (\u001B[38;5;33mMaxPooling1D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m32\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_3 (\u001B[38;5;33mConv1D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │         \u001B[38;5;34m1,552\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_conv_3               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │            \u001B[38;5;34m64\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_conv_3 (\u001B[38;5;33mActivation\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_3 (\u001B[38;5;33mMaxPooling1D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m16\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001B[38;5;33mBidirectional\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m64\u001B[0m)          │        \u001B[38;5;34m12,544\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_lstm (\u001B[38;5;33mDropout\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m64\u001B[0m)          │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_avg_pool                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling1D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m4,160\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense_1              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │           \u001B[38;5;34m256\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense_1 (\u001B[38;5;33mActivation\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense_1 (\u001B[38;5;33mDropout\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense_2              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense_2 (\u001B[38;5;33mActivation\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense_2 (\u001B[38;5;33mDropout\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense_3              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │            \u001B[38;5;34m64\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense_3 (\u001B[38;5;33mActivation\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense_3 (\u001B[38;5;33mDropout\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m17\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_conv_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_conv_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_conv_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pool_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_avg_pool                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_norm_dense_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m28,209\u001B[0m (110.19 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,209</span> (110.19 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m27,761\u001B[0m (108.44 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,761</span> (108.44 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m448\u001B[0m (1.75 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.8594 - loss: 0.4536 - recall: 0.8797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabcneto/.virtualenvs/codigo/lib/python3.10/site-packages/keras/src/callbacks/model_checkpoint.py:302: UserWarning: Can save best model only with val_auc available.\n",
      "  if self._should_save_model(epoch, batch, logs, filepath):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 22ms/step - accuracy: 0.8594 - loss: 0.4535 - recall: 0.8797 - val_accuracy: 0.9033 - val_loss: 0.2526 - val_recall: 0.9480 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.8985 - loss: 0.2555 - recall: 0.9258 - val_accuracy: 0.9033 - val_loss: 0.2229 - val_recall: 0.9554 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.8997 - loss: 0.2315 - recall: 0.9238 - val_accuracy: 0.9022 - val_loss: 0.2182 - val_recall: 0.9484 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.8994 - loss: 0.2251 - recall: 0.9268 - val_accuracy: 0.9038 - val_loss: 0.2101 - val_recall: 0.9521 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.8994 - loss: 0.2226 - recall: 0.9287 - val_accuracy: 0.9044 - val_loss: 0.2134 - val_recall: 0.9462 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.9008 - loss: 0.2189 - recall: 0.9267 - val_accuracy: 0.9027 - val_loss: 0.2065 - val_recall: 0.9397 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9001 - loss: 0.2200 - recall: 0.9302 - val_accuracy: 0.9007 - val_loss: 0.2103 - val_recall: 0.9609 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.8998 - loss: 0.2179 - recall: 0.9336 - val_accuracy: 0.8993 - val_loss: 0.2251 - val_recall: 0.9606 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.8988 - loss: 0.2167 - recall: 0.9332 - val_accuracy: 0.9031 - val_loss: 0.2115 - val_recall: 0.9456 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9017 - loss: 0.2152 - recall: 0.9319 - val_accuracy: 0.9025 - val_loss: 0.2148 - val_recall: 0.9541 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m1143/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9018 - loss: 0.2155 - recall: 0.9348\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 23ms/step - accuracy: 0.9018 - loss: 0.2155 - recall: 0.9348 - val_accuracy: 0.9004 - val_loss: 0.2070 - val_recall: 0.9517 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9039 - loss: 0.2085 - recall: 0.9370 - val_accuracy: 0.9031 - val_loss: 0.2041 - val_recall: 0.9475 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9036 - loss: 0.2059 - recall: 0.9353 - val_accuracy: 0.9028 - val_loss: 0.1963 - val_recall: 0.9436 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9036 - loss: 0.2054 - recall: 0.9360 - val_accuracy: 0.9036 - val_loss: 0.1983 - val_recall: 0.9641 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m41s\u001B[0m 23ms/step - accuracy: 0.9052 - loss: 0.2020 - recall: 0.9353 - val_accuracy: 0.9050 - val_loss: 0.1963 - val_recall: 0.9543 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.9044 - loss: 0.2030 - recall: 0.9346 - val_accuracy: 0.9039 - val_loss: 0.1938 - val_recall: 0.9408 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.9049 - loss: 0.2015 - recall: 0.9327 - val_accuracy: 0.9033 - val_loss: 0.1940 - val_recall: 0.9394 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.9042 - loss: 0.2022 - recall: 0.9375 - val_accuracy: 0.9038 - val_loss: 0.1967 - val_recall: 0.9550 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9049 - loss: 0.2007 - recall: 0.9380 - val_accuracy: 0.9048 - val_loss: 0.1940 - val_recall: 0.9386 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 22ms/step - accuracy: 0.9041 - loss: 0.2006 - recall: 0.9362 - val_accuracy: 0.9047 - val_loss: 0.1939 - val_recall: 0.9410 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 23ms/step - accuracy: 0.9050 - loss: 0.2002 - recall: 0.9372 - val_accuracy: 0.9049 - val_loss: 0.1935 - val_recall: 0.9331 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9048 - loss: 0.2012 - recall: 0.9364 - val_accuracy: 0.9030 - val_loss: 0.1966 - val_recall: 0.9423 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9043 - loss: 0.2008 - recall: 0.9348 - val_accuracy: 0.9037 - val_loss: 0.1964 - val_recall: 0.9510 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 23ms/step - accuracy: 0.9047 - loss: 0.2004 - recall: 0.9382 - val_accuracy: 0.9036 - val_loss: 0.1958 - val_recall: 0.9440 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 22ms/step - accuracy: 0.9051 - loss: 0.1996 - recall: 0.9366 - val_accuracy: 0.9037 - val_loss: 0.1946 - val_recall: 0.9502 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001B[1m1142/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.9051 - loss: 0.1997 - recall: 0.9371\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001B[1m1144/1144\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 23ms/step - accuracy: 0.9051 - loss: 0.1997 - recall: 0.9371 - val_accuracy: 0.9048 - val_loss: 0.1946 - val_recall: 0.9554 - learning_rate: 5.0000e-04\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:37:19.576478Z",
     "start_time": "2025-07-02T23:37:19.113487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Caminho do arquivo onde o modelo foi salvo\n",
    "caminho_modelo_mlp = f\"{RESULTS_DIR}/modelos/mlp_final.h5\"\n",
    "caminho_history_mlp = f\"{RESULTS_DIR}/history/mlp_history.csv\"\n",
    "caminho_modelo_cnn = f\"{RESULTS_DIR}/modelos/cnn_final.h5\"\n",
    "caminho_history_cnn = f\"{RESULTS_DIR}/history/cnn_history.csv\"\n",
    "caminho_modelo_hibrido = f\"{RESULTS_DIR}/modelos/hibrido_final.h5\"\n",
    "caminho_history_hibrido = f\"{RESULTS_DIR}/history/hibrido_history.csv\"\n",
    "\n",
    "# Carregar o modelo híbrido\n",
    "modelo_hibrido_treinado = load_model(caminho_modelo_hibrido)\n",
    "historico_hibrido = pd.read_csv(caminho_history_hibrido)\n",
    "\n",
    "# Carregar o modelo MLP\n",
    "modelo_mlp_treinado = load_model(caminho_modelo_mlp)\n",
    "historico_mlp = pd.read_csv(caminho_history_cnn)\n",
    "\n",
    "# Carregar o modelo CNN\n",
    "modelo_cnn_treinado = load_model(caminho_modelo_cnn)\n",
    "historico_cnn = pd.read_csv(caminho_history_mlp)"
   ],
   "id": "11d43641ef5ca4a1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:37:34.503298Z",
     "start_time": "2025-07-02T23:37:19.593577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Avaliar modelos\n",
    "metricas_mlp, y_pred_mlp, y_prob_mlp = avaliar_modelo(\n",
    "    modelo_mlp_treinado, x_test, y_test, nome_modelo=\"mlp\"\n",
    ")\n",
    "\n",
    "visualizar_historico_treinamento(historico_mlp, \"mlp\")\n",
    "\n",
    "metricas_hibrido, y_pred_hibrido, y_prob_hibrido = avaliar_modelo(\n",
    "    modelo_hibrido_treinado, X_test_cnn, y_test, nome_modelo=\"hibrido\"\n",
    ")\n",
    "\n",
    "visualizar_historico_treinamento(historico_hibrido, \"hibrido\")\n",
    "\n",
    "metricas_cnn, y_pred_cnn, y_prob_cnn = avaliar_modelo(\n",
    "    modelo_cnn_treinado, X_test_cnn, y_test, nome_modelo=\"cnn\"\n",
    ")\n",
    "\n",
    "visualizar_historico_treinamento(historico_cnn, \"cnn\")"
   ],
   "id": "11263b6d85abd65a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:46:31.391896Z",
     "start_time": "2025-07-02T23:37:34.527898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7. Análise de importância de variáveis\n",
    "\n",
    "importancia_mlp = analisar_importancia_variaveis(\n",
    "    modelo_mlp_treinado, x_test, y_test, feature_names, \"mlp\"\n",
    ")\n",
    "\n",
    "importancia_cnn = analisar_importancia_variaveis(\n",
    "    modelo_cnn_treinado, X_test_cnn, y_test, feature_names, \"cnn\"\n",
    ")\n",
    "\n",
    "importancia_hibrido = analisar_importancia_variaveis(\n",
    "    modelo_hibrido_treinado, X_test_cnn, y_test, feature_names, \"hibrido\"\n",
    ")"
   ],
   "id": "490ce0913a1cc511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 872us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 828us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 842us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 833us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 824us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 828us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 852us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 842us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 841us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 847us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 874us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:   8%|▊         | 1/12 [00:09<01:40,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 864us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 851us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 842us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 841us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 850us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 843us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 833us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 846us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 846us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  17%|█▋        | 2/12 [00:18<01:32,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 854us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 855us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 887us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 861us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 882us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 848us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 829us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 855us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 827us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 877us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  25%|██▌       | 3/12 [00:27<01:21,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 859us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 861us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 848us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 854us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 853us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 874us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 858us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 851us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 855us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 845us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  33%|███▎      | 4/12 [00:36<01:12,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 877us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 869us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 870us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 851us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 890us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 851us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 864us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 840us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 849us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 844us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  42%|████▏     | 5/12 [00:45<01:02,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 838us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 848us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 850us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 848us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 850us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 867us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 881us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 889us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 880us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 892us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  50%|█████     | 6/12 [00:53<00:53,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 898us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 980us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 901us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 911us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 891us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 894us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 883us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 885us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 890us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 886us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  58%|█████▊    | 7/12 [01:03<00:44,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 880us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 880us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 870us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 879us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 876us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 887us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 893us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 881us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 887us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 890us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  67%|██████▋   | 8/12 [01:12<00:35,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 884us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 877us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 881us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 900us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 889us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 885us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 895us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 868us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 889us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 885us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  75%|███████▌  | 9/12 [01:21<00:26,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 866us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 874us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 862us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 860us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 886us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 880us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 868us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 896us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 864us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 864us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  83%|████████▎ | 10/12 [01:29<00:17,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 864us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 853us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 871us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 854us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 865us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 881us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 857us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 860us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 872us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 867us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp:  92%|█████████▏| 11/12 [01:39<00:09,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 863us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 866us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 865us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 866us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 852us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 867us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 865us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 862us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 860us/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 877us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - mlp: 100%|██████████| 12/12 [01:47<00:00,  8.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:   8%|▊         | 1/12 [00:11<02:02, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  17%|█▋        | 2/12 [00:21<01:49, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  25%|██▌       | 3/12 [00:32<01:38, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  33%|███▎      | 4/12 [00:43<01:28, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  42%|████▏     | 5/12 [00:55<01:17, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  50%|█████     | 6/12 [01:06<01:06, 11.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  58%|█████▊    | 7/12 [01:17<00:55, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  67%|██████▋   | 8/12 [01:28<00:44, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  75%|███████▌  | 9/12 [01:39<00:33, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  83%|████████▎ | 10/12 [01:50<00:21, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn:  92%|█████████▏| 11/12 [02:00<00:10, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - cnn: 100%|██████████| 12/12 [02:11<00:00, 10.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:   8%|▊         | 1/12 [00:26<04:54, 26.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  17%|█▋        | 2/12 [00:52<04:23, 26.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  25%|██▌       | 3/12 [01:17<03:48, 25.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  33%|███▎      | 4/12 [01:40<03:17, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  42%|████▏     | 5/12 [02:04<02:49, 24.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  50%|█████     | 6/12 [02:27<02:23, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  58%|█████▊    | 7/12 [02:51<01:59, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  67%|██████▋   | 8/12 [03:15<01:36, 24.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  75%|███████▌  | 9/12 [03:38<01:11, 23.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  83%|████████▎ | 10/12 [04:02<00:47, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido:  92%|█████████▏| 11/12 [04:26<00:23, 23.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n",
      "\u001B[1m858/858\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutando features - hibrido: 100%|██████████| 12/12 [04:50<00:00, 24.22s/it]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:47:11.057590Z",
     "start_time": "2025-07-02T23:46:31.431233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8. Análise SHAP\n",
    "explainer_mlp, shap_values_mlp = analisar_shap_values(\n",
    "    modelo_mlp_treinado, x_test, feature_names, \"mlp\"\n",
    ")\n",
    "\n",
    "explainer_cnn, shap_values_cnn = analisar_shap_values(\n",
    "    modelo_cnn_treinado, X_test_cnn, feature_names, \"cnn\"\n",
    ")\n",
    "\n",
    "explainer_cnn, shap_values_cnn = analisar_shap_values(\n",
    "    modelo_cnn_treinado, X_test_cnn, feature_names, \"hibrido\"\n",
    ")"
   ],
   "id": "cd1fea82a171af69",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_126490/1955398360.py:175: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n",
      "/tmp/ipykernel_126490/1955398360.py:189: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n",
      "2025-07-02 20:46:41,454 - __main__ - ERROR - Erro ao calcular SHAP values: 'PermutationExplainer' object has no attribute 'expected_value'\n",
      "PermutationExplainer explainer: 101it [00:15,  2.77it/s]                         \n",
      "/tmp/ipykernel_126490/1955398360.py:175: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n",
      "/tmp/ipykernel_126490/1955398360.py:189: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n",
      "2025-07-02 20:46:58,388 - __main__ - ERROR - Erro ao calcular SHAP values: 'PermutationExplainer' object has no attribute 'expected_value'\n",
      "PermutationExplainer explainer: 101it [00:11,  1.21it/s]                        \n",
      "/tmp/ipykernel_126490/1955398360.py:175: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n",
      "/tmp/ipykernel_126490/1955398360.py:189: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(\n",
      "2025-07-02 20:47:11,021 - __main__ - ERROR - Erro ao calcular SHAP values: 'PermutationExplainer' object has no attribute 'expected_value'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:47:17.409829Z",
     "start_time": "2025-07-02T23:47:11.096923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 9. Análise LIME\n",
    "lime_explainer_mlp = analisar_lime(\n",
    "    modelo_mlp_treinado, x_train, x_test, y_test, feature_names, \"mlp\"\n",
    ")\n",
    "\n",
    "lime_explainer_cnn = analisar_lime(\n",
    "    modelo_cnn_treinado, x_train_cnn, X_test_cnn, y_test, feature_names, \"cnn\"\n",
    ")\n",
    "\n",
    "lime_explainer_hibrido = analisar_lime(\n",
    "    modelo_hibrido_treinado, x_train_cnn, X_test_cnn, y_test, feature_names, \"hibrido\"\n",
    ")\n"
   ],
   "id": "2ab6c489c0660fa9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T23:47:19.222342Z",
     "start_time": "2025-07-02T23:47:17.485787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Corrigir carregamento dos resultados dos modelos clássicos\n",
    "try:\n",
    "    # Tentar carregar o arquivo correto de resultados clássicos\n",
    "    if os.path.exists(f\"{RESULTS_DIR}/resultados_modelos_classicos.csv\"):\n",
    "        resultados_classicos = pd.read_csv(f\"{RESULTS_DIR}/resultados_modelos_classicos.csv\")\n",
    "        logger.info(f\"Resultados clássicos carregados: {len(resultados_classicos)} modelos\")\n",
    "    else:\n",
    "        logger.error(\"Arquivo de resultados clássicos não encontrado\")\n",
    "        # Criar DataFrame vazio com estrutura correta\n",
    "        resultados_classicos = pd.DataFrame(columns=['modelo', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision'])\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao carregar resultados clássicos: {e}\")\n",
    "    resultados_classicos = pd.DataFrame(columns=['modelo', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision'])\n",
    "\n",
    "# 10. Comparação de todos os modelos - com validação de NaN\n",
    "try:\n",
    "    # Verificar se as métricas dos modelos estão disponíveis e válidas\n",
    "    modelos_validos = []\n",
    "\n",
    "    # Validar MLP\n",
    "    if 'metricas_mlp' in locals() and all(key in metricas_mlp for key in ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision']):\n",
    "        if not any(pd.isna(list(metricas_mlp.values()))):\n",
    "            modelos_validos.append({\n",
    "                'modelo': 'MLP',\n",
    "                'accuracy': metricas_mlp['accuracy'],\n",
    "                'balanced_accuracy': metricas_mlp['balanced_accuracy'],\n",
    "                'precision': metricas_mlp['precision'],\n",
    "                'recall': metricas_mlp['recall'],\n",
    "                'f1': metricas_mlp['f1'],\n",
    "                'roc_auc': metricas_mlp['roc_auc'],\n",
    "                'average_precision': metricas_mlp['average_precision']\n",
    "            })\n",
    "            logger.info(\"MLP: métricas válidas adicionadas\")\n",
    "        else:\n",
    "            logger.warning(\"MLP: métricas contêm valores NaN\")\n",
    "    else:\n",
    "        logger.warning(\"MLP: métricas não disponíveis ou incompletas\")\n",
    "\n",
    "    # Validar CNN\n",
    "    if 'metricas_cnn' in locals() and all(key in metricas_cnn for key in ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision']):\n",
    "        if not any(pd.isna(list(metricas_cnn.values()))):\n",
    "            modelos_validos.append({\n",
    "                'modelo': 'CNN',\n",
    "                'accuracy': metricas_cnn['accuracy'],\n",
    "                'balanced_accuracy': metricas_cnn['balanced_accuracy'],\n",
    "                'precision': metricas_cnn['precision'],\n",
    "                'recall': metricas_cnn['recall'],\n",
    "                'f1': metricas_cnn['f1'],\n",
    "                'roc_auc': metricas_cnn['roc_auc'],\n",
    "                'average_precision': metricas_cnn['average_precision']\n",
    "            })\n",
    "            logger.info(\"CNN: métricas válidas adicionadas\")\n",
    "        else:\n",
    "            logger.warning(\"CNN: métricas contêm valores NaN\")\n",
    "    else:\n",
    "        logger.warning(\"CNN: métricas não disponíveis ou incompletas\")\n",
    "\n",
    "    # Validar Híbrido\n",
    "    if 'metricas_hibrido' in locals() and all(key in metricas_hibrido for key in ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision']):\n",
    "        if not any(pd.isna(list(metricas_hibrido.values()))):\n",
    "            modelos_validos.append({\n",
    "                'modelo': 'Híbrido CNN-LSTM',\n",
    "                'accuracy': metricas_hibrido['accuracy'],\n",
    "                'balanced_accuracy': metricas_hibrido['balanced_accuracy'],\n",
    "                'precision': metricas_hibrido['precision'],\n",
    "                'recall': metricas_hibrido['recall'],\n",
    "                'f1': metricas_hibrido['f1'],\n",
    "                'roc_auc': metricas_hibrido['roc_auc'],\n",
    "                'average_precision': metricas_hibrido['average_precision']\n",
    "            })\n",
    "            logger.info(\"Híbrido: métricas válidas adicionadas\")\n",
    "        else:\n",
    "            logger.warning(\"Híbrido: métricas contêm valores NaN\")\n",
    "    else:\n",
    "        logger.warning(\"Híbrido: métricas não disponíveis ou incompletas\")\n",
    "\n",
    "    # Criar DataFrame com modelos válidos\n",
    "    if modelos_validos:\n",
    "        resultados_redes = pd.DataFrame(modelos_validos)\n",
    "        logger.info(f\"Criado DataFrame com {len(resultados_redes)} modelos de redes neurais válidos\")\n",
    "    else:\n",
    "        logger.warning(\"Nenhum modelo de rede neural válido encontrado\")\n",
    "        resultados_redes = pd.DataFrame(columns=['modelo', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'roc_auc', 'average_precision'])\n",
    "\n",
    "    # Executar comparação apenas se houver dados válidos\n",
    "    if len(resultados_classicos) > 0 or len(resultados_redes) > 0:\n",
    "        comparar_todos_modelos(resultados_classicos, resultados_redes)\n",
    "        logger.info(\"Comparação de modelos executada com sucesso\")\n",
    "    else:\n",
    "        logger.error(\"Nenhum resultado válido disponível para comparação\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro na comparação de modelos: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ],
   "id": "c4794cdd955c285f",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
